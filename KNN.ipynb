{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np, matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import json\n",
    "import sys\n",
    "from scipy import stats\n",
    "from sklearn.cross_validation import *\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "smalldf = pd.read_csv(\"small.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bID</th>\n",
       "      <th>pID</th>\n",
       "      <th>AB</th>\n",
       "      <th>H</th>\n",
       "      <th>PA</th>\n",
       "      <th>RL</th>\n",
       "      <th>SAC</th>\n",
       "      <th>SO</th>\n",
       "      <th>TB</th>\n",
       "      <th>W</th>\n",
       "      <th>matchID</th>\n",
       "      <th>AVG</th>\n",
       "      <th>OBP</th>\n",
       "      <th>ov_AB</th>\n",
       "      <th>ov_H</th>\n",
       "      <th>ov_PA</th>\n",
       "      <th>ov_SAC</th>\n",
       "      <th>ov_SO</th>\n",
       "      <th>ov_TB</th>\n",
       "      <th>ov_W</th>\n",
       "      <th>ov_FACED</th>\n",
       "      <th>ov_AVG</th>\n",
       "      <th>ov_OBP</th>\n",
       "      <th>ov_SO_PCT</th>\n",
       "      <th>ov_W_PCT</th>\n",
       "      <th>ov_H_PCT</th>\n",
       "      <th>ovp_AB</th>\n",
       "      <th>ovp_H</th>\n",
       "      <th>ovp_PA</th>\n",
       "      <th>ovp_SAC</th>\n",
       "      <th>ovp_SO</th>\n",
       "      <th>ovp_TB</th>\n",
       "      <th>ovp_W</th>\n",
       "      <th>ovp_FACED</th>\n",
       "      <th>ovp_SO_PCT</th>\n",
       "      <th>ovp_W_PCT</th>\n",
       "      <th>ovp_H_PCT</th>\n",
       "      <th>ovp_AVG</th>\n",
       "      <th>ovp_OBP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>schic002</td>\n",
       "      <td>benea001</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>schic002_benea001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>146</td>\n",
       "      <td>22</td>\n",
       "      <td>150</td>\n",
       "      <td>14</td>\n",
       "      <td>57</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>0.150685</td>\n",
       "      <td>0.173333</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.026667</td>\n",
       "      <td>0.146667</td>\n",
       "      <td>3046</td>\n",
       "      <td>827</td>\n",
       "      <td>3425</td>\n",
       "      <td>46</td>\n",
       "      <td>609</td>\n",
       "      <td>1713</td>\n",
       "      <td>379</td>\n",
       "      <td>136</td>\n",
       "      <td>0.177810</td>\n",
       "      <td>0.110657</td>\n",
       "      <td>0.241460</td>\n",
       "      <td>0.271504</td>\n",
       "      <td>0.352117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>schic002</td>\n",
       "      <td>browk001</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>R</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>schic002_browk001</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>146</td>\n",
       "      <td>22</td>\n",
       "      <td>150</td>\n",
       "      <td>14</td>\n",
       "      <td>57</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>0.150685</td>\n",
       "      <td>0.173333</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.026667</td>\n",
       "      <td>0.146667</td>\n",
       "      <td>4582</td>\n",
       "      <td>1159</td>\n",
       "      <td>4989</td>\n",
       "      <td>47</td>\n",
       "      <td>892</td>\n",
       "      <td>1974</td>\n",
       "      <td>407</td>\n",
       "      <td>222</td>\n",
       "      <td>0.178793</td>\n",
       "      <td>0.081579</td>\n",
       "      <td>0.232311</td>\n",
       "      <td>0.252946</td>\n",
       "      <td>0.313891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>schic002</td>\n",
       "      <td>fassj001</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>L</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>schic002_fassj001</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>146</td>\n",
       "      <td>22</td>\n",
       "      <td>150</td>\n",
       "      <td>14</td>\n",
       "      <td>57</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>0.150685</td>\n",
       "      <td>0.173333</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.026667</td>\n",
       "      <td>0.146667</td>\n",
       "      <td>3006</td>\n",
       "      <td>847</td>\n",
       "      <td>3357</td>\n",
       "      <td>40</td>\n",
       "      <td>582</td>\n",
       "      <td>1587</td>\n",
       "      <td>351</td>\n",
       "      <td>185</td>\n",
       "      <td>0.173369</td>\n",
       "      <td>0.104558</td>\n",
       "      <td>0.252309</td>\n",
       "      <td>0.281770</td>\n",
       "      <td>0.356866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>schic002</td>\n",
       "      <td>glavt001</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>L</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>schic002_glavt001</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>146</td>\n",
       "      <td>22</td>\n",
       "      <td>150</td>\n",
       "      <td>14</td>\n",
       "      <td>57</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>0.150685</td>\n",
       "      <td>0.173333</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.026667</td>\n",
       "      <td>0.146667</td>\n",
       "      <td>7561</td>\n",
       "      <td>2115</td>\n",
       "      <td>8413</td>\n",
       "      <td>102</td>\n",
       "      <td>985</td>\n",
       "      <td>3852</td>\n",
       "      <td>852</td>\n",
       "      <td>280</td>\n",
       "      <td>0.117081</td>\n",
       "      <td>0.101272</td>\n",
       "      <td>0.251397</td>\n",
       "      <td>0.279725</td>\n",
       "      <td>0.352668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>schic002</td>\n",
       "      <td>hampm001</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>L</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>schic002_hampm001</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>146</td>\n",
       "      <td>22</td>\n",
       "      <td>150</td>\n",
       "      <td>14</td>\n",
       "      <td>57</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>0.150685</td>\n",
       "      <td>0.173333</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.026667</td>\n",
       "      <td>0.146667</td>\n",
       "      <td>4782</td>\n",
       "      <td>1361</td>\n",
       "      <td>5339</td>\n",
       "      <td>53</td>\n",
       "      <td>666</td>\n",
       "      <td>2355</td>\n",
       "      <td>557</td>\n",
       "      <td>232</td>\n",
       "      <td>0.124742</td>\n",
       "      <td>0.104327</td>\n",
       "      <td>0.254917</td>\n",
       "      <td>0.284609</td>\n",
       "      <td>0.359243</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        bID       pID  AB  H  PA RL  SAC  SO  TB  W            matchID       AVG       OBP  ov_AB  ov_H  ov_PA  ov_SAC  ov_SO  ov_TB  ov_W  ov_FACED    ov_AVG    ov_OBP  ov_SO_PCT  ov_W_PCT  ov_H_PCT  ovp_AB  ovp_H  ovp_PA  ovp_SAC  ovp_SO  ovp_TB  ovp_W  ovp_FACED  ovp_SO_PCT  ovp_W_PCT  ovp_H_PCT   ovp_AVG   ovp_OBP\n",
       "0  schic002  benea001   9  0   9  R    1   4   0  0  schic002_benea001  0.000000  0.000000    146    22    150      14     57     30     4        14  0.150685  0.173333       0.38  0.026667  0.146667    3046    827    3425       46     609    1713    379        136    0.177810   0.110657   0.241460  0.271504  0.352117\n",
       "1  schic002  browk001  11  1  11  R    0   6   1  0  schic002_browk001  0.090909  0.090909    146    22    150      14     57     30     4        14  0.150685  0.173333       0.38  0.026667  0.146667    4582   1159    4989       47     892    1974    407        222    0.178793   0.081579   0.232311  0.252946  0.313891\n",
       "2  schic002  fassj001  11  2  11  L    1   5   4  0  schic002_fassj001  0.181818  0.181818    146    22    150      14     57     30     4        14  0.150685  0.173333       0.38  0.026667  0.146667    3006    847    3357       40     582    1587    351        185    0.173369   0.104558   0.252309  0.281770  0.356866\n",
       "3  schic002  glavt001  14  3  14  L    1   3   5  0  schic002_glavt001  0.214286  0.214286    146    22    150      14     57     30     4        14  0.150685  0.173333       0.38  0.026667  0.146667    7561   2115    8413      102     985    3852    852        280    0.117081   0.101272   0.251397  0.279725  0.352668\n",
       "4  schic002  hampm001  16  2  16  L    1   6   2  0  schic002_hampm001  0.125000  0.125000    146    22    150      14     57     30     4        14  0.150685  0.173333       0.38  0.026667  0.146667    4782   1361    5339       53     666    2355    557        232    0.124742   0.104327   0.254917  0.284609  0.359243"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smalldf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_supports(df):\n",
    "    ubids=df.bID.unique()\n",
    "    pitch = df.groupby('pID').bID.unique()\n",
    "    bdict={}\n",
    "    for e,v in zip(pitch.index.values, pitch.values):\n",
    "        bdict[e] = np.array([item in v for item in ubids])\n",
    "    pitchers=bdict.keys()\n",
    "    supports=[]\n",
    "    for i,p1 in enumerate(pitchers):\n",
    "        for j,p2 in enumerate(pitchers):\n",
    "            if  i < j:\n",
    "                supmask = (bdict[p1] & bdict[p2])\n",
    "                common_batters = np.sum(supmask)\n",
    "                supports.append(common_batters)\n",
    "    print \"mean support\",np.mean(supports), \"median support\", np.median(supports)\n",
    "    return supports, bdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def recompute_frame(ldf):\n",
    "    \"\"\"\n",
    "    takes a dataframe ldf, makes a copy of it, and returns the copy\n",
    "    with all conglomerations recomputed\n",
    "    this is used when a frame is subsetted.\n",
    "    \"\"\"\n",
    "    ldfb=ldf.groupby('bID')\n",
    "    ldfp=ldf.groupby('pID')\n",
    "    nldf=ldf.copy()\n",
    "    #Conglomerate pitcher stats\n",
    "    nldf.set_index(['pID'], inplace=True)\n",
    "    for col in ['AB', 'PA', 'H', 'TB', 'SAC', 'SO', 'W']:\n",
    "        nldf['ovp_'+col] = ldfp[col].sum()\n",
    "    nldf['ovp_AVG'] = nldf['ovp_H']/nldf['ovp_AB']\n",
    "    nldf['ovp_FACED']= ldfp.AB.count()\n",
    "    nldf['ovp_OBP'] = (nldf['ovp_H'] + nldf['ovp_W'])/nldf['ovp_PA']\n",
    "    for col in ['SO', 'W', 'H']:\n",
    "        nldf['ovp_' + col + '_PCT'] = nldf['ovp_' + col] / nldf['ovp_PA']\n",
    "    nldf.reset_index(inplace=True)\n",
    "    \n",
    "    #Conglomerate batter stats\n",
    "    nldf.set_index(['bID'], inplace=True)\n",
    "    for col in ['AB', 'PA', 'H', 'TB', 'SAC', 'SO', 'W']:\n",
    "        nldf['ov_'+col] = ldfb[col].sum()\n",
    "    nldf['ov_AVG'] = nldf['ov_H']/nldf['ov_AB']\n",
    "    nldf['ov_FACED']= ldfb.AB.count()\n",
    "    nldf['ov_OBP'] = (nldf['ov_H'] + nldf['ov_W'])/nldf['ov_PA']\n",
    "    for col in ['SO', 'W', 'H']:\n",
    "        nldf['ov_' + col + '_PCT'] = nldf['ov_' + col] / nldf['ov_PA']\n",
    "    nldf.reset_index(inplace=True)\n",
    "    return nldf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_smaller(df, pacountp, pacountb):\n",
    "    smallidf1=df[(df.ovp_PA > pacountp) & (df.ov_PA > pacountb)]\n",
    "    smalldf=recompute_frame(smallidf1)\n",
    "    return smalldf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_smaller_2(df, col, limit, greater=True):\n",
    "    if greater:\n",
    "        smallidf = df[(df[col] > limit)]\n",
    "    else:\n",
    "        smallidf = df[(df[col] < limit)]\n",
    "    return recompute_frame(smallidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into test and training sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(109688, 39)"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(88234, 39)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print smalldf.shape,\n",
    "smalldf[smalldf.ov_FACED > 100].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(101036, 39) (4944, 39) (3708, 39)\n"
     ]
    }
   ],
   "source": [
    "trainlist=[]\n",
    "testlist=[]\n",
    "validatelist=[]\n",
    "take=21 #21 matchups between validation and test set\n",
    "for k, v in smalldf.groupby('bID'):\n",
    "    if len(v) > 100: #batter has faced at least 150 pitchers\n",
    "        train_rows, test_valid_rows = train_test_split(v, test_size=take)\n",
    "        trainlist.append(train_rows)\n",
    "        valid_rows, test_rows = train_test_split(test_valid_rows, test_size=0.4)\n",
    "        validatelist.append(valid_rows) \n",
    "        testlist.append(test_rows) \n",
    "    else:\n",
    "        trainlist.append(v)\n",
    "traindf=pd.concat(trainlist)\n",
    "validatedf=pd.concat(validatelist)\n",
    "testdf=pd.concat(testlist)\n",
    "print traindf.shape, validatedf.shape, testdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n"
     ]
    }
   ],
   "source": [
    "#Make sure each pitcher ID was encountered in training set\n",
    "maskval= np.in1d(validatedf.pID, traindf.pID) \n",
    "masktest = np.in1d(testdf.pID, traindf.pID)\n",
    "print np.sum(~maskval), np.sum(~masktest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bID</th>\n",
       "      <th>pID</th>\n",
       "      <th>AB</th>\n",
       "      <th>H</th>\n",
       "      <th>PA</th>\n",
       "      <th>RL</th>\n",
       "      <th>SAC</th>\n",
       "      <th>SO</th>\n",
       "      <th>TB</th>\n",
       "      <th>W</th>\n",
       "      <th>matchID</th>\n",
       "      <th>AVG</th>\n",
       "      <th>OBP</th>\n",
       "      <th>ov_AB</th>\n",
       "      <th>ov_H</th>\n",
       "      <th>ov_PA</th>\n",
       "      <th>ov_SAC</th>\n",
       "      <th>ov_SO</th>\n",
       "      <th>ov_TB</th>\n",
       "      <th>ov_W</th>\n",
       "      <th>ov_FACED</th>\n",
       "      <th>ov_AVG</th>\n",
       "      <th>ov_OBP</th>\n",
       "      <th>ov_SO_PCT</th>\n",
       "      <th>ov_W_PCT</th>\n",
       "      <th>ov_H_PCT</th>\n",
       "      <th>ovp_AB</th>\n",
       "      <th>ovp_H</th>\n",
       "      <th>ovp_PA</th>\n",
       "      <th>ovp_SAC</th>\n",
       "      <th>ovp_SO</th>\n",
       "      <th>ovp_TB</th>\n",
       "      <th>ovp_W</th>\n",
       "      <th>ovp_FACED</th>\n",
       "      <th>ovp_SO_PCT</th>\n",
       "      <th>ovp_W_PCT</th>\n",
       "      <th>ovp_H_PCT</th>\n",
       "      <th>ovp_AVG</th>\n",
       "      <th>ovp_OBP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aberb001</td>\n",
       "      <td>bellr003</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>R</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>aberb001_bellr003</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>359</td>\n",
       "      <td>78</td>\n",
       "      <td>385</td>\n",
       "      <td>4</td>\n",
       "      <td>41</td>\n",
       "      <td>120</td>\n",
       "      <td>26</td>\n",
       "      <td>30</td>\n",
       "      <td>0.21727</td>\n",
       "      <td>0.27013</td>\n",
       "      <td>0.106494</td>\n",
       "      <td>0.067532</td>\n",
       "      <td>0.202597</td>\n",
       "      <td>1460</td>\n",
       "      <td>443</td>\n",
       "      <td>1648</td>\n",
       "      <td>19</td>\n",
       "      <td>210</td>\n",
       "      <td>1004</td>\n",
       "      <td>188</td>\n",
       "      <td>125</td>\n",
       "      <td>0.127427</td>\n",
       "      <td>0.114078</td>\n",
       "      <td>0.268811</td>\n",
       "      <td>0.303425</td>\n",
       "      <td>0.382888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aberb001</td>\n",
       "      <td>buehm001</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>L</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>aberb001_buehm001</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>359</td>\n",
       "      <td>78</td>\n",
       "      <td>385</td>\n",
       "      <td>4</td>\n",
       "      <td>41</td>\n",
       "      <td>120</td>\n",
       "      <td>26</td>\n",
       "      <td>30</td>\n",
       "      <td>0.21727</td>\n",
       "      <td>0.27013</td>\n",
       "      <td>0.106494</td>\n",
       "      <td>0.067532</td>\n",
       "      <td>0.202597</td>\n",
       "      <td>9014</td>\n",
       "      <td>2506</td>\n",
       "      <td>9658</td>\n",
       "      <td>126</td>\n",
       "      <td>1316</td>\n",
       "      <td>4670</td>\n",
       "      <td>644</td>\n",
       "      <td>414</td>\n",
       "      <td>0.136260</td>\n",
       "      <td>0.066680</td>\n",
       "      <td>0.259474</td>\n",
       "      <td>0.278012</td>\n",
       "      <td>0.326154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aberb001</td>\n",
       "      <td>burkj001</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>R</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>aberb001_burkj001</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>359</td>\n",
       "      <td>78</td>\n",
       "      <td>385</td>\n",
       "      <td>4</td>\n",
       "      <td>41</td>\n",
       "      <td>120</td>\n",
       "      <td>26</td>\n",
       "      <td>30</td>\n",
       "      <td>0.21727</td>\n",
       "      <td>0.27013</td>\n",
       "      <td>0.106494</td>\n",
       "      <td>0.067532</td>\n",
       "      <td>0.202597</td>\n",
       "      <td>3889</td>\n",
       "      <td>1124</td>\n",
       "      <td>4252</td>\n",
       "      <td>52</td>\n",
       "      <td>644</td>\n",
       "      <td>2135</td>\n",
       "      <td>363</td>\n",
       "      <td>211</td>\n",
       "      <td>0.151458</td>\n",
       "      <td>0.085372</td>\n",
       "      <td>0.264346</td>\n",
       "      <td>0.289020</td>\n",
       "      <td>0.349718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aberb001</td>\n",
       "      <td>castf001</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>R</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>aberb001_castf001</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>359</td>\n",
       "      <td>78</td>\n",
       "      <td>385</td>\n",
       "      <td>4</td>\n",
       "      <td>41</td>\n",
       "      <td>120</td>\n",
       "      <td>26</td>\n",
       "      <td>30</td>\n",
       "      <td>0.21727</td>\n",
       "      <td>0.27013</td>\n",
       "      <td>0.106494</td>\n",
       "      <td>0.067532</td>\n",
       "      <td>0.202597</td>\n",
       "      <td>2101</td>\n",
       "      <td>600</td>\n",
       "      <td>2329</td>\n",
       "      <td>29</td>\n",
       "      <td>335</td>\n",
       "      <td>1210</td>\n",
       "      <td>228</td>\n",
       "      <td>143</td>\n",
       "      <td>0.143839</td>\n",
       "      <td>0.097896</td>\n",
       "      <td>0.257621</td>\n",
       "      <td>0.285578</td>\n",
       "      <td>0.355517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aberb001</td>\n",
       "      <td>clemr001</td>\n",
       "      <td>25</td>\n",
       "      <td>7</td>\n",
       "      <td>26</td>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>aberb001_clemr001</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>359</td>\n",
       "      <td>78</td>\n",
       "      <td>385</td>\n",
       "      <td>4</td>\n",
       "      <td>41</td>\n",
       "      <td>120</td>\n",
       "      <td>26</td>\n",
       "      <td>30</td>\n",
       "      <td>0.21727</td>\n",
       "      <td>0.27013</td>\n",
       "      <td>0.106494</td>\n",
       "      <td>0.067532</td>\n",
       "      <td>0.202597</td>\n",
       "      <td>6218</td>\n",
       "      <td>1515</td>\n",
       "      <td>6880</td>\n",
       "      <td>63</td>\n",
       "      <td>1470</td>\n",
       "      <td>2828</td>\n",
       "      <td>662</td>\n",
       "      <td>265</td>\n",
       "      <td>0.213663</td>\n",
       "      <td>0.096221</td>\n",
       "      <td>0.220203</td>\n",
       "      <td>0.243647</td>\n",
       "      <td>0.316424</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        bID       pID  AB  H  PA RL  SAC  SO  TB  W            matchID       AVG       OBP  ov_AB  ov_H  ov_PA  ov_SAC  ov_SO  ov_TB  ov_W  ov_FACED   ov_AVG   ov_OBP  ov_SO_PCT  ov_W_PCT  ov_H_PCT  ovp_AB  ovp_H  ovp_PA  ovp_SAC  ovp_SO  ovp_TB  ovp_W  ovp_FACED  ovp_SO_PCT  ovp_W_PCT  ovp_H_PCT   ovp_AVG   ovp_OBP\n",
       "0  aberb001  bellr003   9  1  10  R    0   0   1  1  aberb001_bellr003  0.111111  0.200000    359    78    385       4     41    120    26        30  0.21727  0.27013   0.106494  0.067532  0.202597    1460    443    1648       19     210    1004    188        125    0.127427   0.114078   0.268811  0.303425  0.382888\n",
       "1  aberb001  buehm001  13  2  14  L    0   3   6  1  aberb001_buehm001  0.153846  0.214286    359    78    385       4     41    120    26        30  0.21727  0.27013   0.106494  0.067532  0.202597    9014   2506    9658      126    1316    4670    644        414    0.136260   0.066680   0.259474  0.278012  0.326154\n",
       "2  aberb001  burkj001   8  2   9  R    0   1   2  1  aberb001_burkj001  0.250000  0.333333    359    78    385       4     41    120    26        30  0.21727  0.27013   0.106494  0.067532  0.202597    3889   1124    4252       52     644    2135    363        211    0.151458   0.085372   0.264346  0.289020  0.349718\n",
       "3  aberb001  castf001   7  1  11  R    0   0   1  4  aberb001_castf001  0.142857  0.454545    359    78    385       4     41    120    26        30  0.21727  0.27013   0.106494  0.067532  0.202597    2101    600    2329       29     335    1210    228        143    0.143839   0.097896   0.257621  0.285578  0.355517\n",
       "4  aberb001  clemr001  25  7  26  R    1   2   9  1  aberb001_clemr001  0.280000  0.307692    359    78    385       4     41    120    26        30  0.21727  0.27013   0.106494  0.067532  0.202597    6218   1515    6880       63    1470    2828    662        265    0.213663   0.096221   0.220203  0.243647  0.316424"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindf=recompute_frame(traindf)\n",
    "validatedf=recompute_frame(validatedf)\n",
    "testdf=recompute_frame(testdf)\n",
    "validatedf=validatedf[['bID', 'pID','AVG']]\n",
    "testdf=testdf[['bID', 'pID', 'AVG']]\n",
    "traindf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27389865959721776"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ybar = traindf.H.sum() / float(traindf.AB.sum())\n",
    "ybar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bIDs=traindf.bID.unique()#unique-user-ids\n",
    "pIDs=traindf.pID.unique()#unique-item-ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bidmap={v:k for k,v in enumerate(bIDs)}#of length U\n",
    "pidmap={v:k for k,v in enumerate(pIDs)}#of length M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate dictionaries of pitcher and batter biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batter_biases = {}\n",
    "pitcher_biases = {}\n",
    "\n",
    "for u_index, u_id in enumerate(bids):\n",
    "    batter_rows = traindf[traindf.bID == b_id]\n",
    "    y_u = batter_rows.user_avg.unique()[0]\n",
    "    u_baseline = y_u - ybar\n",
    "    user_biases[u_id] = u_baseline\n",
    "    \n",
    "for i_index, i_id in enumerate(uiids):\n",
    "    item_rows = traindf[traindf.business_id == i_id]\n",
    "    y_i = item_rows.business_avg.unique()[0]\n",
    "    i_baseline = y_i - ybar\n",
    "    item_biases[i_id] = i_baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare results function from pset 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compare_results(stars_actual, stars_predicted, ylow=1, yhigh=6, model=\"\", predicteds=False, onsame=False, axis=False):\n",
    "    \"\"\"\n",
    "    plot predicted results against actual results. Takes 2 arguments: a\n",
    "    numpy array of actual ratings and a numpy array of predicted ratings\n",
    "    scatterplots the predictions, a unit slope line, line segments joining the mean,\n",
    "    and a filled in area of the standard deviations.\"\n",
    "    \"\"\"\n",
    "    if onsame:\n",
    "        ax=onsame\n",
    "    elif axis:\n",
    "        ax=axis\n",
    "    else:\n",
    "        fig=plt.figure()\n",
    "        ax=plt.gca()\n",
    "    df=pd.DataFrame(dict(actual=stars_actual, predicted=stars_predicted))\n",
    "    xp=[]\n",
    "    yp=[]\n",
    "    for k,v in df.groupby('actual'):\n",
    "        xp.append(k)\n",
    "        yp.append(v.predicted.mean())        \n",
    "    cl, = ax.plot(xp,yp, 's-', label=\"means for %s\" % model)\n",
    "    c=cl.get_color()\n",
    "    sig=df.groupby('actual').predicted.std().values\n",
    "    ax.fill_between(xp, yp - sig, yp + sig, color=c, alpha=0.2)\n",
    "    if predicteds:\n",
    "        ax.plot(df.actual, df.predicted, '.', color=c, alpha=0.1, label=\"predicted for %s\" % model)\n",
    "\n",
    "    if not onsame:\n",
    "        ax.plot([1,5],[1,5], 'k', label=\"slope 1\")\n",
    "        ax.set_xlabel(\"actual\")\n",
    "        ax.set_ylabel(\"predicted\")\n",
    "        ax.set_ylim([ylow,yhigh])\n",
    "        ax.set_xlim([0.9, 5.1])\n",
    "    ax.legend(frameon=False, loc=\"upper left\")\n",
    "    rmse=get_rmse(stars_actual, stars_predicted)\n",
    "    print \"RMSE for %s\" % model, rmse\n",
    "    return ax,rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is an idea for a function that can be used to determine batter similarity. The function takes the batter-pitcher pair to predict, and it returns similar batters who have faced the given pitcher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sim_batters(bID, pID, df):\n",
    "    batter_row = df.loc[df['bID'] == bID]\n",
    "    AVG = batter_row['AVG']\n",
    "    OBP = batter_row['OBP']\n",
    "    if (batter_row['RL'] == 'R'):\n",
    "        hand = 0\n",
    "    else:\n",
    "        hand = 1\n",
    "    SAC = batter_row['SAC']\n",
    "    # continue for other statistics\n",
    "    \n",
    "    # find list of bIDs who have faced given pID\n",
    "    p_batters = df.loc[df['pID'] == pID]\n",
    "    \n",
    "    similarity = {}\n",
    "    # for each batter, calculate similarity\n",
    "    for b in p_batters:\n",
    "        comp_b_row = df.loc[df['bID'] == b]\n",
    "        comp_AVG = batter_row['AVG']\n",
    "        comp_OBP = batter_row['OBP']\n",
    "        if (batter_row['RL'] == 'R'):\n",
    "            comp_hand = 0\n",
    "        else:\n",
    "            comp_hand = 1\n",
    "        comp_SAC = batter_row['SAC']\n",
    "        # continue for other statistics\n",
    "        \n",
    "        #calculate similarity\n",
    "        AVG_score = AVG_weight*(AVG - comp_AVG)/AVG\n",
    "        OBP_score = OBP_weight*(OBP - comp_OPB)/OBP\n",
    "        if (hand == comp_hand):\n",
    "            hand_score = hand_weight\n",
    "        else:\n",
    "             hand_score = 0   \n",
    "        SAC_score = SAC_weight*(SAC - comp_SAC)/SAC\n",
    "        total_score = AVG_score + OBP_score + hand_score + SAC_score\n",
    "        similarity[b] = total_score\n",
    "    # return top x bIDs with lowest scores\n",
    "    sorted_sim = sorted(similarity.items(), key=operator.itemgetter(1))\n",
    "    sim_batters = sorted_sim.keys\n",
    "    return sim_batters[:10]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are functions from pset 4 that might be useful for the KNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats.stats import pearsonr\n",
    "# calculate pearson sim between 2 pitchers\n",
    "def pearson_sim(pitcher1, pitcher2, n_common):\n",
    "    p1_avg = pitcher1['ov_AVG']\n",
    "    p2_avg = pitcher2['ov_AVG']\n",
    "    p1_actual = pitcher1['AVG']\n",
    "    p2_actual = pitcher2['AVG']\n",
    "    norm1 = []\n",
    "    norm2 = []\n",
    "    for i in range(len(rest1)):\n",
    "        norm1.append(rest1[i] - p1_actual[i])\n",
    "        norm2.append(rest2[i] - p2_actual[i])\n",
    "    if (n_common == 0) or (n_common==1):\n",
    "        rho = 0;\n",
    "    else:\n",
    "        rho = sp.stats.pearsonr(norm1,norm2)[0]\n",
    "    if np.isnan(rho):\n",
    "        return 0;\n",
    "    return rho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_restaurant_reviews(pID, df, set_of_batters):\n",
    "    \"\"\"\n",
    "    given a pitcher id and a set of batters, return the sub-dataframe of their\n",
    "    averages.\n",
    "    \"\"\"\n",
    "    mask = (df.user_id.isin(set_of_batters)) & (df.pID==pID)\n",
    "    avgs = df[mask]\n",
    "    avgs = avgs[avgs.user_id.duplicated()==False]\n",
    "    return avgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Database:\n",
    "    \"A class representing a database of similarities and common supports\"\n",
    "    \n",
    "    def __init__(self, rindexmap, supports):\n",
    "        \"the constructor, takes a map of restaurant id's to integers\"\n",
    "        database={}\n",
    "        self.rindexmap=rindexmap\n",
    "        self.supports=supports\n",
    "        l_keys=len(self.rindexmap.keys())\n",
    "        self.database_sim=np.zeros([l_keys,l_keys])\n",
    "        self.database_sup=np.zeros([l_keys, l_keys], dtype=np.int)\n",
    "\n",
    "    def set_supports(self, supports):\n",
    "        self.supports=supports\n",
    "        \n",
    "    def get(self, b1, b2):\n",
    "        \"returns a tuple of similarity,common_support given two business ids\"\n",
    "        sim=self.database_sim[self.rindexmap[b1]][self.rindexmap[b2]]\n",
    "        nsup=self.database_sup[self.rindexmap[b1]][self.rindexmap[b2]]\n",
    "        return (sim, nsup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'uiidmap' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-cec2aee98e59>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDatabase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muiidmap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msupports\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'uiidmap' is not defined"
     ]
    }
   ],
   "source": [
    "db=Database(uiidmap, supports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mapper1(row):\n",
    "    return row[1], (row[2], row[5], row[14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def combiner(items):\n",
    "    indict={}\n",
    "    for key, value in items:\n",
    "        if not indict.has_key(key):\n",
    "            indict[key]=[]\n",
    "        indict[key].append(value)\n",
    "    return indict.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reducer1(the_input):\n",
    "    bID, values = the_input\n",
    "    avgs=[]\n",
    "    for pID,AVG,ov_AVG in values:\n",
    "        avgs.append((pID,(AVG, ov_AVG)))\n",
    "    return bID, avgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from itertools import combinations_with_replacement\n",
    "def mapper2(list_input):\n",
    "    nlist = []\n",
    "    comb = list(combinations_with_replacement(list_input[1], 2))\n",
    "    for item in comb:\n",
    "        if item[0][0] > item[1][0]:\n",
    "            biz_pair = item[1][0], item[0][0]\n",
    "            star_pair = item[1][1], item[0][1]\n",
    "        else:\n",
    "            biz_pair = item[0][0], item[1][0]\n",
    "            star_pair = item[0][1], item[1][1]\n",
    "        tup = (biz_pair, star_pair)\n",
    "        nlist.append(tup)\n",
    "    return nlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def combiner_list(itemslist):\n",
    "    indict={}\n",
    "    for items in itemslist:\n",
    "        for key, value in items:\n",
    "            if not indict.has_key(key):\n",
    "                indict[key]=[]\n",
    "            indict[key].append(value)\n",
    "    return indict.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reducer2(item_dict):\n",
    "    p1_id = item_dict[0][0]\n",
    "    p2_id = item_dict[0][1]\n",
    "    AVG_1 = [x[0][0] for x in item_dict[1]]\n",
    "    AVG_2 = [x[1][0] for x in item_dict[1]]\n",
    "    ov_AVG_1 = [x[0][1] for x in item_dict[1]]\n",
    "    ov_AVG_2 = [x[1][1] for x in item_dict[1]]\n",
    "    n_common = len(item_dict[1])\n",
    "    p1_dict = {'ov_AVG': ov_AVG_1, 'AVG': AVG_1}\n",
    "    p2_dict = {'ov_AVG': ov_AVG_2, 'AVG': AVG_2}\n",
    "    rho = pearson_sim(p1_dict, p2_dict, n_common)\n",
    "    return (p1_id, p2_id),(rho, n_common)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def map_reduce(tuples):\n",
    "    mapped1=map(mapper1, tuples)\n",
    "    combine1=combiner(mapped1)\n",
    "    reduced1=reduce(lambda x,y: x + [reducer1(y)], combine1, [])\n",
    "    mapped2=map(mapper2,reduced1)\n",
    "    combine2=combiner_list(mapped2)\n",
    "    output=reduce(lambda x,y: x + [reducer2(y)], combine2, [])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-05bad35a5c75>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtuples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraindf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitertuples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmap_reduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-50-5391d317792c>\u001b[0m in \u001b[0;36mmap_reduce\u001b[0;34m(tuples)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mcombine1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcombiner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mreduced1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mreducer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcombine1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mmapped2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapper2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreduced1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mcombine2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcombiner_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mreducer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcombine2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-47-942c0d203844>\u001b[0m in \u001b[0;36mmapper2\u001b[0;34m(list_input)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mbiz_pair\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             \u001b[0mstar_pair\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mbiz_pair\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tuples=traindf.itertuples()\n",
    "sims=map_reduce(tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def populate_from_mr(db, df, mapredlist):\n",
    "    for tpair,vpair in mapredlist:\n",
    "        i1=db.rindexmap[tpair[0]]\n",
    "        i2=db.rindexmap[tpair[1]]\n",
    "        db.database_sim[i1][i2]=vpair[0]\n",
    "        db.database_sup[i1][i2]=vpair[1]\n",
    "        db.database_sim[i2][i1]=vpair[0]\n",
    "        db.database_sup[i2][i1]=vpair[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "populate_from_mr(db, traindf, sims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking work with populate_by_calculating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "db2=Database( uiidmap, supports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_similarity(db, df, p1, p2, similarity_func):\n",
    "    # find common reviewers\n",
    "    common_reviewers = db.supports[db.rindexmap[p1]][db.rindexmap[p2]]\n",
    "    n_common=len(common_reviewers)\n",
    "    if p1==p2:\n",
    "        return 1., n_common\n",
    "    #get reviews\n",
    "    p1_ov_AVG = get_restaurant_reviews(p1, df, common_reviewers)\n",
    "    p2_ov_AVG = get_restaurant_reviews(p2, df, common_reviewers)\n",
    "    sim=similarity_func(p1_ov_AVG, p2_ov_AVG, n_common)\n",
    "    return sim, n_common\n",
    "\n",
    "def populate_by_calculating(db, df, similarity_func):\n",
    "    \"\"\"\n",
    "    a populator for every pair of businesses in df. takes similarity_func like\n",
    "    pearson_sim as argument\n",
    "    \"\"\"\n",
    "    items=db.rindexmap.items()\n",
    "    for b1, i1 in items:\n",
    "        for b2, i2 in items:\n",
    "            if i1 <= i2:\n",
    "                sim, nsup=calculate_similarity(db, df, b1, b2, similarity_func)\n",
    "                db.database_sim[i1][i2]=sim\n",
    "                db.database_sim[i2][i1]=sim\n",
    "                db.database_sup[i1][i2]=nsup\n",
    "                db.database_sup[i2][i1]=nsup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "populate_by_calculating(db2, traindf, pearson_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tpair=('FV0BkoGOd3Yu_eJnXY15ZA', 'O-Xa9GCFWI65YiBD5Jw_hA')\n",
    "print db.get(tpair[0],tpair[1]),db2.get(tpair[0],tpair[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shrunk_sim(sim, n_common, reg=3.):\n",
    "    \"takes a similarity and shrinks it down by using the regularizer\"\n",
    "    ssim=(n_common*sim)/(n_common+reg)\n",
    "    return ssim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function\n",
    "--------\n",
    "knearest\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "restaurant_id : string\n",
    "    The id of the restaurant whose nearest neighbors we want\n",
    "set_of_restaurants : array\n",
    "    The set of restaurants from which we want to find the nearest neighbors\n",
    "dbase : instance of Database class.\n",
    "    A database of similarities, on which the get method can be used to get the similarity\n",
    "  of two businesses. e.g. dbase.get(rid1,rid2)\n",
    "k : int\n",
    "    the number of nearest neighbors desired, default 7\n",
    "reg: float\n",
    "    the regularization.\n",
    "    \n",
    "  \n",
    "Returns\n",
    "--------\n",
    "A sorted list\n",
    "    of the top k similar restaurants. The list is a list of tuples\n",
    "    (business_id, shrunken similarity, common support).\n",
    "\"\"\"\n",
    "from operator import itemgetter\n",
    "def knearest(restaurant_id, set_of_restaurants, dbase, k=7, reg=3.):\n",
    "    \"\"\"\n",
    "    Given a restaurant_id, dataframe, and database, get a sorted list of the\n",
    "    k most similar restaurants from the set of restaurants.\n",
    "    \"\"\"\n",
    "    similars=[]\n",
    "    for other_rest_id in set_of_restaurants:\n",
    "        if other_rest_id!=restaurant_id:\n",
    "            sim, nc=dbase.get(restaurant_id, other_rest_id)\n",
    "            ssim=shrunk_sim(sim, nc, reg=reg)\n",
    "            simdist=(1. - ssim)/2.\n",
    "            similars.append((other_rest_id, simdist, nc ))\n",
    "    similars=sorted(similars, key=itemgetter(1))\n",
    "    return similars[0:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_users_restaurants(df, user_id):\n",
    "    dfuser=df[df.user_id==user_id]\n",
    "    dfuserdedup=dfuser.drop_duplicates('business_id')\n",
    "    return dict(zip(dfuserdedup.business_id.values, dfuserdedup.stars.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function\n",
    "--------\n",
    "rating\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "set_of_restaurants: Dictionary\n",
    "    The dictionary of restaurant: star-rating pairs you want to make the prediction from.\n",
    "    This would be the output of a function like get_users_restaurants\n",
    "train_map: Dictionary\n",
    "    A dictionary with keys mean, users and items which have estimates of\n",
    "    overall average or intercept, user coefficients(averages), and\n",
    "    item coefficients(averages) respectively\n",
    "dbase : instance of Database class.\n",
    "    A database of similarities, on which the get method can be used to get the similarity\n",
    "  of two businessed. e.g. dbase.get(rid1,rid2)\n",
    "restaurant_id : string\n",
    "    The id of the restaurant whose nearest neighbors we want\n",
    "user_id : string\n",
    "    The id of the user, in whose reviewed restaurants we want to find the neighbors\n",
    "k : int\n",
    "    the number of nearest neighbors desired, default 7\n",
    "reg: float\n",
    "    the regularization.\n",
    "    \n",
    "  \n",
    "Returns\n",
    "--------\n",
    "A float\n",
    "    which is the imputed rating that we predict that user_id will make for restaurant_id\n",
    "    \n",
    "Notes\n",
    "--------\n",
    "If the sum of scores is 0, return the baseline estimate of the ranking.\n",
    "\"\"\"\n",
    "#your code here\n",
    "# Note: this function was inspired in part by the solutions to the 2013 hw4\n",
    "def rating(set_of_restaurants, train_map, dbase, restaurant_id, user_id, k=7, reg=3.):\n",
    "    mu=train_map['mean']\n",
    "    user_bias = train_map['users'][user_id]\n",
    "    nsum=0.\n",
    "    scoresum=0.\n",
    "    nears=knearest(restaurant_id, set_of_restaurants, dbase, k=k, reg=reg)\n",
    "    restaurant_bias=train_map['items'][restaurant_id]\n",
    "    scores=[]\n",
    "    for r,s,nc in nears:\n",
    "        ssim = 1-s\n",
    "        scoresum=scoresum+ssim\n",
    "        scores.append(ssim)\n",
    "        r_biases = train_map['items'][r]\n",
    "        r_stars = set_of_restaurants[r]\n",
    "        rminusb=(r_stars - (r_biases + user_bias + mu))\n",
    "        nsum=nsum+ssim*rminusb\n",
    "    baseline=(user_bias +restaurant_bias + mu)\n",
    "    if scoresum > 0.:\n",
    "        val =  nsum/scoresum + baseline\n",
    "    else:\n",
    "        val=baseline\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainuser=traindf.loc[0].user_id\n",
    "testrest=testdf[testdf.user_id==trainuser].business_id.values[0]\n",
    "print trainuser, testrest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_actual(df, userid, bizid):\n",
    "    return df[(df.user_id==userid) & (df.business_id==bizid)]['stars'].values[0]\n",
    "\n",
    "print \"Actual\", get_actual(testdf, trainuser, testrest)\n",
    "print \"Predicted\",rating(get_users_restaurants(traindf, trainuser), train_avgs, db, testrest, trainuser, k=2, reg=3.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_ratings_user_nbd(indf, traindf, train_map, db, k=2, reg=3.):\n",
    "    zips=zip(indf.business_id, indf.user_id, indf.stars)\n",
    "    preds=[]\n",
    "    actuals=[]\n",
    "    for (r,u,actual) in zips:\n",
    "        pred=rating(get_users_restaurants(traindf, u),train_map, db, r,u, k, reg)\n",
    "        preds.append(pred)\n",
    "        actuals.append(actual)\n",
    "    return np.array(preds), np.array(actuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pt, at = get_ratings_user_nbd(traindf, traindf, train_avgs, db, k=4, reg=4.)\n",
    "compare_results(at,pt, model=\"knn(user) on training k=4, reg=4\", predicteds=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
