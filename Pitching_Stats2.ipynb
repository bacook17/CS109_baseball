{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Loading in appropriate packages\n",
    "import numpy as np, matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "import sys\n",
    "from scipy import stats\n",
    "from sklearn.cross_validation import *\n",
    "\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.notebook_repr_html', True)\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"poster\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Loading in Relevant Dataframes\n",
    "master = pd.read_csv('data/lahman/Master.csv')\n",
    "pitching = pd.read_csv('data/lahman/Pitching.csv')\n",
    "smalldf = pd.read_csv('data/small.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For details on the Lahman file columns, see \"2.3: Pitching Table\": http://seanlahman.com/files/database/readme2014.txt\n",
    "\n",
    "pitcher_sums is just the \"sums\", so be sure to recalculate things like ERA and BAOpp that don't add linearly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Ben's intro code\n",
    "retro_to_lah = dict(zip(master['retroID'], master['playerID']))\n",
    "#retro_to_hand = dict(zip(master['retroID'], master['throws']))\n",
    "#pitcherIDs = smalldf['pID'].unique()#RetroIDs\n",
    "#L_pitcherIDs = [retro_to_lah[name] for name in pitcherIDs] #LahmanIDs\n",
    "#grouped =  pitching.groupby('playerID').sum().reset_index()\n",
    "#mask = np.in1d(grouped.playerID, L_pitcherIDs)\n",
    "#pitcher_sums = grouped[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bID</th>\n",
       "      <th>pID</th>\n",
       "      <th>AB</th>\n",
       "      <th>H</th>\n",
       "      <th>PA</th>\n",
       "      <th>RL</th>\n",
       "      <th>SAC</th>\n",
       "      <th>SO</th>\n",
       "      <th>TB</th>\n",
       "      <th>W</th>\n",
       "      <th>matchID</th>\n",
       "      <th>AVG</th>\n",
       "      <th>OBP</th>\n",
       "      <th>ov_AB</th>\n",
       "      <th>ov_H</th>\n",
       "      <th>ov_PA</th>\n",
       "      <th>ov_SAC</th>\n",
       "      <th>ov_SO</th>\n",
       "      <th>ov_TB</th>\n",
       "      <th>ov_W</th>\n",
       "      <th>ov_AVG</th>\n",
       "      <th>ov_OBP</th>\n",
       "      <th>ov_FACED</th>\n",
       "      <th>ov_SO_PCT</th>\n",
       "      <th>ov_W_PCT</th>\n",
       "      <th>ov_H_PCT</th>\n",
       "      <th>ovp_AB</th>\n",
       "      <th>ovp_H</th>\n",
       "      <th>ovp_PA</th>\n",
       "      <th>ovp_SAC</th>\n",
       "      <th>ovp_SO</th>\n",
       "      <th>ovp_TB</th>\n",
       "      <th>ovp_W</th>\n",
       "      <th>ovp_AVG</th>\n",
       "      <th>ovp_OBP</th>\n",
       "      <th>ovp_FACED</th>\n",
       "      <th>ovp_SO_PCT</th>\n",
       "      <th>ovp_W_PCT</th>\n",
       "      <th>ovp_H_PCT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>schic002</td>\n",
       "      <td>benea001</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>schic002_benea001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>146</td>\n",
       "      <td>22</td>\n",
       "      <td>150</td>\n",
       "      <td>14</td>\n",
       "      <td>57</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>0.150685</td>\n",
       "      <td>0.173333</td>\n",
       "      <td>14</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.026667</td>\n",
       "      <td>0.146667</td>\n",
       "      <td>3046</td>\n",
       "      <td>827</td>\n",
       "      <td>3425</td>\n",
       "      <td>46</td>\n",
       "      <td>609</td>\n",
       "      <td>1713</td>\n",
       "      <td>379</td>\n",
       "      <td>0.271504</td>\n",
       "      <td>0.352117</td>\n",
       "      <td>136</td>\n",
       "      <td>0.177810</td>\n",
       "      <td>0.110657</td>\n",
       "      <td>0.241460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>schic002</td>\n",
       "      <td>browk001</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>R</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>schic002_browk001</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>146</td>\n",
       "      <td>22</td>\n",
       "      <td>150</td>\n",
       "      <td>14</td>\n",
       "      <td>57</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>0.150685</td>\n",
       "      <td>0.173333</td>\n",
       "      <td>14</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.026667</td>\n",
       "      <td>0.146667</td>\n",
       "      <td>4582</td>\n",
       "      <td>1159</td>\n",
       "      <td>4989</td>\n",
       "      <td>47</td>\n",
       "      <td>892</td>\n",
       "      <td>1974</td>\n",
       "      <td>407</td>\n",
       "      <td>0.252946</td>\n",
       "      <td>0.313891</td>\n",
       "      <td>222</td>\n",
       "      <td>0.178793</td>\n",
       "      <td>0.081579</td>\n",
       "      <td>0.232311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>schic002</td>\n",
       "      <td>fassj001</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>L</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>schic002_fassj001</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>146</td>\n",
       "      <td>22</td>\n",
       "      <td>150</td>\n",
       "      <td>14</td>\n",
       "      <td>57</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>0.150685</td>\n",
       "      <td>0.173333</td>\n",
       "      <td>14</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.026667</td>\n",
       "      <td>0.146667</td>\n",
       "      <td>3006</td>\n",
       "      <td>847</td>\n",
       "      <td>3357</td>\n",
       "      <td>40</td>\n",
       "      <td>582</td>\n",
       "      <td>1587</td>\n",
       "      <td>351</td>\n",
       "      <td>0.281770</td>\n",
       "      <td>0.356866</td>\n",
       "      <td>185</td>\n",
       "      <td>0.173369</td>\n",
       "      <td>0.104558</td>\n",
       "      <td>0.252309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>schic002</td>\n",
       "      <td>glavt001</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>L</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>schic002_glavt001</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>146</td>\n",
       "      <td>22</td>\n",
       "      <td>150</td>\n",
       "      <td>14</td>\n",
       "      <td>57</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>0.150685</td>\n",
       "      <td>0.173333</td>\n",
       "      <td>14</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.026667</td>\n",
       "      <td>0.146667</td>\n",
       "      <td>7561</td>\n",
       "      <td>2115</td>\n",
       "      <td>8413</td>\n",
       "      <td>102</td>\n",
       "      <td>985</td>\n",
       "      <td>3852</td>\n",
       "      <td>852</td>\n",
       "      <td>0.279725</td>\n",
       "      <td>0.352668</td>\n",
       "      <td>280</td>\n",
       "      <td>0.117081</td>\n",
       "      <td>0.101272</td>\n",
       "      <td>0.251397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>schic002</td>\n",
       "      <td>hampm001</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>L</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>schic002_hampm001</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>146</td>\n",
       "      <td>22</td>\n",
       "      <td>150</td>\n",
       "      <td>14</td>\n",
       "      <td>57</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>0.150685</td>\n",
       "      <td>0.173333</td>\n",
       "      <td>14</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.026667</td>\n",
       "      <td>0.146667</td>\n",
       "      <td>4782</td>\n",
       "      <td>1361</td>\n",
       "      <td>5339</td>\n",
       "      <td>53</td>\n",
       "      <td>666</td>\n",
       "      <td>2355</td>\n",
       "      <td>557</td>\n",
       "      <td>0.284609</td>\n",
       "      <td>0.359243</td>\n",
       "      <td>232</td>\n",
       "      <td>0.124742</td>\n",
       "      <td>0.104327</td>\n",
       "      <td>0.254917</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        bID       pID  AB  H  PA RL  SAC  SO  TB  W            matchID       AVG       OBP  ov_AB  ov_H  ov_PA  ov_SAC  ov_SO  ov_TB  ov_W    ov_AVG    ov_OBP  ov_FACED  ov_SO_PCT  ov_W_PCT  ov_H_PCT  ovp_AB  ovp_H  ovp_PA  ovp_SAC  ovp_SO  ovp_TB  ovp_W   ovp_AVG   ovp_OBP  ovp_FACED  ovp_SO_PCT  ovp_W_PCT  ovp_H_PCT\n",
       "0  schic002  benea001   9  0   9  R    1   4   0  0  schic002_benea001  0.000000  0.000000    146    22    150      14     57     30     4  0.150685  0.173333        14       0.38  0.026667  0.146667    3046    827    3425       46     609    1713    379  0.271504  0.352117        136    0.177810   0.110657   0.241460\n",
       "1  schic002  browk001  11  1  11  R    0   6   1  0  schic002_browk001  0.090909  0.090909    146    22    150      14     57     30     4  0.150685  0.173333        14       0.38  0.026667  0.146667    4582   1159    4989       47     892    1974    407  0.252946  0.313891        222    0.178793   0.081579   0.232311\n",
       "2  schic002  fassj001  11  2  11  L    1   5   4  0  schic002_fassj001  0.181818  0.181818    146    22    150      14     57     30     4  0.150685  0.173333        14       0.38  0.026667  0.146667    3006    847    3357       40     582    1587    351  0.281770  0.356866        185    0.173369   0.104558   0.252309\n",
       "3  schic002  glavt001  14  3  14  L    1   3   5  0  schic002_glavt001  0.214286  0.214286    146    22    150      14     57     30     4  0.150685  0.173333        14       0.38  0.026667  0.146667    7561   2115    8413      102     985    3852    852  0.279725  0.352668        280    0.117081   0.101272   0.251397\n",
       "4  schic002  hampm001  16  2  16  L    1   6   2  0  schic002_hampm001  0.125000  0.125000    146    22    150      14     57     30     4  0.150685  0.173333        14       0.38  0.026667  0.146667    4782   1361    5339       53     666    2355    557  0.284609  0.359243        232    0.124742   0.104327   0.254917"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smalldf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>playerID</th>\n",
       "      <th>yearID</th>\n",
       "      <th>stint</th>\n",
       "      <th>teamID</th>\n",
       "      <th>lgID</th>\n",
       "      <th>W</th>\n",
       "      <th>L</th>\n",
       "      <th>G</th>\n",
       "      <th>GS</th>\n",
       "      <th>CG</th>\n",
       "      <th>SHO</th>\n",
       "      <th>SV</th>\n",
       "      <th>IPouts</th>\n",
       "      <th>H</th>\n",
       "      <th>ER</th>\n",
       "      <th>HR</th>\n",
       "      <th>BB</th>\n",
       "      <th>SO</th>\n",
       "      <th>BAOpp</th>\n",
       "      <th>ERA</th>\n",
       "      <th>IBB</th>\n",
       "      <th>WP</th>\n",
       "      <th>HBP</th>\n",
       "      <th>BK</th>\n",
       "      <th>BFP</th>\n",
       "      <th>GF</th>\n",
       "      <th>R</th>\n",
       "      <th>SH</th>\n",
       "      <th>SF</th>\n",
       "      <th>GIDP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bechtge01</td>\n",
       "      <td>1871</td>\n",
       "      <td>1</td>\n",
       "      <td>PH1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>78</td>\n",
       "      <td>43</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.96</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>brainas01</td>\n",
       "      <td>1871</td>\n",
       "      <td>1</td>\n",
       "      <td>WS3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>792</td>\n",
       "      <td>361</td>\n",
       "      <td>132</td>\n",
       "      <td>4</td>\n",
       "      <td>37</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fergubo01</td>\n",
       "      <td>1871</td>\n",
       "      <td>1</td>\n",
       "      <td>NY2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fishech01</td>\n",
       "      <td>1871</td>\n",
       "      <td>1</td>\n",
       "      <td>RC1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>639</td>\n",
       "      <td>295</td>\n",
       "      <td>103</td>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>257</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fleetfr01</td>\n",
       "      <td>1871</td>\n",
       "      <td>1</td>\n",
       "      <td>NY2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    playerID  yearID  stint teamID lgID   W   L   G  GS  CG  SHO  SV  IPouts    H   ER  HR  BB  SO  BAOpp    ERA  IBB  WP  HBP  BK  BFP  GF    R  SH  SF  GIDP\n",
       "0  bechtge01    1871      1    PH1  NaN   1   2   3   3   2    0   0      78   43   23   0  11   1    NaN   7.96  NaN NaN  NaN   0  NaN NaN   42 NaN NaN   NaN\n",
       "1  brainas01    1871      1    WS3  NaN  12  15  30  30  30    0   0     792  361  132   4  37  13    NaN   4.50  NaN NaN  NaN   0  NaN NaN  292 NaN NaN   NaN\n",
       "2  fergubo01    1871      1    NY2  NaN   0   0   1   0   0    0   0       3    8    3   0   0   0    NaN  27.00  NaN NaN  NaN   0  NaN NaN    9 NaN NaN   NaN\n",
       "3  fishech01    1871      1    RC1  NaN   4  16  24  24  22    1   0     639  295  103   3  31  15    NaN   4.35  NaN NaN  NaN   0  NaN NaN  257 NaN NaN   NaN\n",
       "4  fleetfr01    1871      1    NY2  NaN   0   1   1   1   1    0   0      27   20   10   0   3   0    NaN  10.00  NaN NaN  NaN   0  NaN NaN   21 NaN NaN   NaN"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pitching.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Pitchers Similarity Formula\n",
    "\n",
    "Start with a thousand and then subtract the following:\n",
    "\n",
    "One point for each difference of 1 win.\n",
    "\n",
    "One point for each difference of 2 losses.\n",
    "\n",
    "One point for each difference of .002 in winning percentage (max 100 points).\n",
    "\n",
    "One point for each difference of .02 in ERA (max 100 points).\n",
    "\n",
    "One point for each difference of 10 games pitched.\n",
    "\n",
    "One point for each difference of 20 starts.\n",
    "\n",
    "One point for each difference of 20 complete games.\n",
    "\n",
    "One point for each difference of 50 innings pitched.\n",
    "\n",
    "One point for each difference of 50 hits allowed.\n",
    "\n",
    "One point for each difference of 30 strikeouts.\n",
    "\n",
    "One point for each difference of 10 walks.\n",
    "\n",
    "One point for each difference of 5 shutouts.\n",
    "\n",
    "One point for each difference of 3 saves.\n",
    "\n",
    "If they throw with a different hand and are starters subtract 10, relievers 25. For relievers you halve the winning percentage penalty. For all pitchers, the winning percentage penalty can be no larger than 1.5 times the wins and losses penalty. Relievers are defined as more relief appearances than starts and less than 4.00 innings per appearance.\n",
    "\n",
    "We plugged all this in to create the lists you see on the player pages. Note that a player must have 100 innings pitched or 500 at bats before being considered, and to be truly accurate you need to look at whole careers, but it is fun to speculate all the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##input is the pitcherIDs\n",
    "def pitcher_sim_alt(p1name, p2name, pitching, same_hand=True):\n",
    "    listed= [p1name,p2name]\n",
    "    two_pitcherIDs= [retro_to_lah[name] for name in listed] #getting the lahman ids for the 2 pitcher ids to use in Pitching Dataframe\n",
    "\n",
    "    grouped2 =  pitching.groupby('playerID').sum().reset_index() #getting the summed data for each unique playerID\n",
    "    mask2 = np.in1d(grouped2.playerID, two_pitcherIDs) #creating a mask for the 2 pitcher IDs needed\n",
    "    pitchers=grouped2[mask2].reset_index() #resetting the index to 0,1 to make concatenating dataframes easier\n",
    "    pitchers.ERA = 9.*(pitchers.ER)/(pitchers.IPouts / 3.) #generating ERA \n",
    "    pitchers.BAOpp = (pitchers.H + pitchers.BB + pitchers.IBB + pitchers.HBP) / pitchers.BFP #batting average against\n",
    "    pitchers['WiP'] = pitchers.W/pitchers.G #win percentage\n",
    "    pitchers['IP'] = pitchers.IPouts/3. #innings pitched\n",
    "    \n",
    "    #determining whether a pitcher is a relief pitcher based on whether more games started than not \n",
    "    #and less than 4 innings pitched per game\n",
    "    pitchers['Games']=pitchers['GS']-pitchers['G']/2. #if positive, more games started than games in relief\n",
    "    pitchers['inningsper']=pitchers['IP']/pitchers['G'] #innings per game \n",
    "    relief=[]\n",
    "    for i in pitchers.iterrows():\n",
    "        if i[1]['Games']<0. and i[1]['inningsper']<4.:\n",
    "            relief.append(1.)\n",
    "        else:\n",
    "            relief.append(0.)\n",
    "    dfrel=pd.DataFrame({'REL':relief})\n",
    "    \n",
    "    #adding handedness and whether a pitcher is a relief pitcher to the dataframe \n",
    "    final=pitchers.join([dfhands,dfrel], how='outer')\n",
    "    \n",
    "    #getting the 2 rows from the final dataframe to perform calculations \n",
    "    p1=final[final.playerID==two_pitcherIDs[0]]\n",
    "    p2=final[final.playerID==two_pitcherIDs[1]]\n",
    "    \n",
    "    \n",
    "    #Wins and Losses Penalties\n",
    "    win_diff=np.abs(int(p1['W'])-int(p2['W'])) #1 pt for each win\n",
    "    loss_diff=np.abs(int(p1['L'])-int(p2['L']))/2. #1 pt each 2 losses\n",
    "    \n",
    "    #Winning Percentage Penalty\n",
    "    if int(p1['REL'])==1:     #winning percentage is halved for relief pitchers\n",
    "        p1['WiP']=p1['WiP']/2.\n",
    "    if int(p2['REL'])==1:\n",
    "        p2['WiP']=p2['WiP']/2.\n",
    "    wip_diff=np.abs(float(p1['WiP'])-float(p2['WiP']))/.002 #1 pt diff of winning percentage of 0.002 \n",
    "    if wip_diff > 1.5*(win_diff+loss_diff): #winning percentage cannot be more than 1.5 times the penalties for win/loss differences \n",
    "        wip_diff= 1.5*(win_diff+loss_diff)\n",
    "    if wip_diff >100: #penalty for winning percentage has a max= 100\n",
    "        wip_diff=100   \n",
    "    era_diff=np.abs(float(p1['ERA'])-float(p2['ERA']))/0.02 #1 pt diff of ERA of 0.02\n",
    "    if era_diff >100:\n",
    "        era_diff=100 #max =100\n",
    "    \n",
    "    #Handedness Penalties conditional on both pitchers being relief pitchers or not \n",
    "    if list(p1['RL'])[0]!=list(p2['RL'])[0] and int(p1['REL'])==0 and int(p2['REL'])==0: #handedness is different, relief pitchers\n",
    "        hand_diff=10. \n",
    "    elif list(p1['RL'])[0]!=list(p2['RL'])[0] and int(p1['REL'])==1 and int(p2['REL'])==1.: #handedness is different, starters\n",
    "        hand_diff=25.  \n",
    "    else:\n",
    "        hand_diff=0.\n",
    "    \n",
    "    #Additional Penalties\n",
    "    gp_diff=np.abs(int(p1['G'])-int(p2['G']))/10. #1 pt for diff of 10 games played\n",
    "    st_diff=np.abs(int(p1['GS'])-int(p2['GS']))/20. #1 pt for diff of 20 games started\n",
    "    cg_diff=np.abs(int(p1['CG'])-int(p2['CG']))/20. #1 pt for diff of 20 games completed\n",
    "    ip_diff=np.abs(float(p1['IP'])-float(p2['IP']))/50. #1 pt for diff of 50 innings pitched\n",
    "    h_diff=np.abs(int(p1['H'])-int(p2['H']))/50. #1 pt for diff of 50 hits allowed\n",
    "    sp_diff=np.abs(int(p1['SO'])-int(p2['SO']))/30. #1 pt for diff of 30 strikeouts\n",
    "    bb_diff=np.abs(int(p1['BB'])-int(p2['BB']))/50. #1 pt for diff of 10 walks\n",
    "    sho_diff=np.abs(int(p1['SHO'])-int(p2['SHO']))/5. #1 pt for diff of 5 shutouts\n",
    "    sv_diff=np.abs(int(p1['SV'])-int(p2['SV']))/3. #1 pt for diff of 3 saves\n",
    "    \n",
    "\n",
    "    score=1000 #generating starting score and subtracting penalties\n",
    "    final_score=score-(win_diff+loss_diff+wip_diff+era_diff+gp_diff+st_diff+cg_diff+\n",
    "                       ip_diff+h_diff+sp_diff+bb_diff+sho_diff+sv_diff+hand_diff)\n",
    "    #print final_score\n",
    "\n",
    "    return final_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##input is the smalldf rows corresponding to the 2 pitcher ids\n",
    "def pitcher_sim(p1_matchups, p2_matchups, n_common=0):\n",
    "    p1name=list(p1_matchups['pID'][:1])[0]  #getting the IDs for both pitchers\n",
    "    p2name=list(p2_matchups['pID'][:1])[0]\n",
    "    dfhands=pd.DataFrame({'RL':[list(p1_matchups['RL'][:1])[0],list(p2_matchups['RL'][:1])[0]]}) #retrieving handedness from  smalldf\n",
    "    listed= [p1name,p2name]\n",
    "    two_pitcherIDs= [retro_to_lah[name] for name in listed] #getting the lahman ids for the 2 pitcher ids to use in Pitching Dataframe\n",
    "\n",
    "    grouped2 =  pitching.groupby('playerID').sum().reset_index() #getting the summed data for each unique playerID\n",
    "    mask2 = np.in1d(grouped2.playerID, two_pitcherIDs) #creating a mask for the 2 pitcher IDs needed\n",
    "    pitchers=grouped2[mask2].reset_index() #resetting the index to 0,1 to make concatenating dataframes easier\n",
    "    pitchers.ERA = 9.*(pitchers.ER)/(pitchers.IPouts / 3.) #generating ERA \n",
    "    pitchers.BAOpp = (pitchers.H + pitchers.BB + pitchers.IBB + pitchers.HBP) / pitchers.BFP #batting average against\n",
    "    pitchers['WiP'] = pitchers.W/pitchers.G #win percentage\n",
    "    pitchers['IP'] = pitchers.IPouts/3. #innings pitched\n",
    "    \n",
    "    #determining whether a pitcher is a relief pitcher based on whether more games started than not \n",
    "    #and less than 4 innings pitched per game\n",
    "    pitchers['Games']=pitchers['GS']-pitchers['G']/2. #if positive, more games started than games in relief\n",
    "    pitchers['inningsper']=pitchers['IP']/pitchers['G'] #innings per game \n",
    "    relief=[]\n",
    "    for i in pitchers.iterrows():\n",
    "        if i[1]['Games']<0. and i[1]['inningsper']<4.:\n",
    "            relief.append(1.)\n",
    "        else:\n",
    "            relief.append(0.)\n",
    "    dfrel=pd.DataFrame({'REL':relief})\n",
    "    \n",
    "    #adding handedness and whether a pitcher is a relief pitcher to the dataframe \n",
    "    final=pitchers.join([dfhands,dfrel], how='outer')\n",
    "    \n",
    "    #getting the 2 rows from the final dataframe to perform calculations \n",
    "    p1=final[final.playerID==two_pitcherIDs[0]]\n",
    "    p2=final[final.playerID==two_pitcherIDs[1]]\n",
    "    \n",
    "    \n",
    "    #Wins and Losses Penalties\n",
    "    win_diff=np.abs(int(p1['W'])-int(p2['W'])) #1 pt for each win\n",
    "    loss_diff=np.abs(int(p1['L'])-int(p2['L']))/2. #1 pt each 2 losses\n",
    "    \n",
    "    #Winning Percentage Penalty\n",
    "    if int(p1['REL'])==1:     #winning percentage is halved for relief pitchers\n",
    "        p1['WiP']=p1['WiP']/2.\n",
    "    if int(p2['REL'])==1:\n",
    "        p2['WiP']=p2['WiP']/2.\n",
    "    wip_diff=np.abs(float(p1['WiP'])-float(p2['WiP']))/.002 #1 pt diff of winning percentage of 0.002 \n",
    "    if wip_diff > 1.5*(win_diff+loss_diff): #winning percentage cannot be more than 1.5 times the penalties for win/loss differences \n",
    "        wip_diff= 1.5*(win_diff+loss_diff)\n",
    "    if wip_diff >100: #penalty for winning percentage has a max= 100\n",
    "        wip_diff=100   \n",
    "    era_diff=np.abs(float(p1['ERA'])-float(p2['ERA']))/0.02 #1 pt diff of ERA of 0.02\n",
    "    if era_diff >100:\n",
    "        era_diff=100 #max =100\n",
    "    \n",
    "    #Handedness Penalties conditional on both pitchers being relief pitchers or not \n",
    "    if list(p1['RL'])[0]!=list(p2['RL'])[0] and int(p1['REL'])==0 and int(p2['REL'])==0: #handedness is different, relief pitchers\n",
    "        hand_diff=10. \n",
    "    elif list(p1['RL'])[0]!=list(p2['RL'])[0] and int(p1['REL'])==1 and int(p2['REL'])==1.: #handedness is different, starters\n",
    "        hand_diff=25.  \n",
    "    else:\n",
    "        hand_diff=0.\n",
    "    \n",
    "    #Additional Penalties\n",
    "    gp_diff=np.abs(int(p1['G'])-int(p2['G']))/10. #1 pt for diff of 10 games played\n",
    "    st_diff=np.abs(int(p1['GS'])-int(p2['GS']))/20. #1 pt for diff of 20 games started\n",
    "    cg_diff=np.abs(int(p1['CG'])-int(p2['CG']))/20. #1 pt for diff of 20 games completed\n",
    "    ip_diff=np.abs(float(p1['IP'])-float(p2['IP']))/50. #1 pt for diff of 50 innings pitched\n",
    "    h_diff=np.abs(int(p1['H'])-int(p2['H']))/50. #1 pt for diff of 50 hits allowed\n",
    "    sp_diff=np.abs(int(p1['SO'])-int(p2['SO']))/30. #1 pt for diff of 30 strikeouts\n",
    "    bb_diff=np.abs(int(p1['BB'])-int(p2['BB']))/50. #1 pt for diff of 10 walks\n",
    "    sho_diff=np.abs(int(p1['SHO'])-int(p2['SHO']))/5. #1 pt for diff of 5 shutouts\n",
    "    sv_diff=np.abs(int(p1['SV'])-int(p2['SV']))/3. #1 pt for diff of 3 saves\n",
    "    \n",
    "\n",
    "    score=1000 #generating starting score and subtracting penalties\n",
    "    final_score=score-(win_diff+loss_diff+wip_diff+era_diff+gp_diff+st_diff+cg_diff+\n",
    "                       ip_diff+h_diff+sp_diff+bb_diff+sho_diff+sv_diff+hand_diff)\n",
    "    #print final_score\n",
    "\n",
    "    return final_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a, b = np.random.choice(smalldf.pID.unique(), size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 32s, sys: 5.03 s, total: 1min 37s\n",
      "Wall time: 1min 38s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bcook/anaconda/lib/python2.7/site-packages/IPython/kernel/__main__.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/bcook/anaconda/lib/python2.7/site-packages/IPython/kernel/__main__.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in np.arange(1000):\n",
    "    p1, p2 = np.random.choice(smalldf.pID.unique(), size=2)\n",
    "    pitcher_sim(smalldf[smalldf.pID==p1],smalldf[smalldf.pID==p2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Using Mapreduce to see if this works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_restaurant_reviews(pID, df, set_of_batters):\n",
    "    \"\"\"\n",
    "    given a pitcher id and a set of batters, return the sub-dataframe of their\n",
    "    averages.\n",
    "    \"\"\"\n",
    "    mask = (df.bID.isin(set_of_batters)) & (df.pID==pID)\n",
    "    avgs = df[mask]\n",
    "    avgs = avgs[avgs.bID.duplicated()==False]\n",
    "    return avgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(109688, 39)"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(88234, 39)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print smalldf.shape,\n",
    "smalldf[smalldf.ov_FACED > 100].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(101036, 39) (4944, 39) (3708, 39)\n"
     ]
    }
   ],
   "source": [
    "trainlist=[]\n",
    "testlist=[]\n",
    "validatelist=[]\n",
    "take=21 #21 matchups between validation and test set\n",
    "for k, v in smalldf.groupby('bID'):\n",
    "    if len(v) > 100: #batter has faced at least 150 pitchers\n",
    "        train_rows, test_valid_rows = train_test_split(v, test_size=take)\n",
    "        trainlist.append(train_rows)\n",
    "        valid_rows, test_rows = train_test_split(test_valid_rows, test_size=0.4)\n",
    "        validatelist.append(valid_rows) \n",
    "        testlist.append(test_rows) \n",
    "    else:\n",
    "        trainlist.append(v)\n",
    "traindf=pd.concat(trainlist)\n",
    "validatedf=pd.concat(validatelist)\n",
    "testdf=pd.concat(testlist)\n",
    "print traindf.shape, validatedf.shape, testdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n"
     ]
    }
   ],
   "source": [
    "#Make sure each pitcher ID was encountered in training set\n",
    "maskval= np.in1d(validatedf.pID, traindf.pID) \n",
    "masktest = np.in1d(testdf.pID, traindf.pID)\n",
    "print np.sum(~maskval), np.sum(~masktest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def recompute_frame(ldf):\n",
    "    \"\"\"\n",
    "    takes a dataframe ldf, makes a copy of it, and returns the copy\n",
    "    with all conglomerations recomputed\n",
    "    this is used when a frame is subsetted.\n",
    "    \"\"\"\n",
    "    ldfb=ldf.groupby('bID')\n",
    "    ldfp=ldf.groupby('pID')\n",
    "    nldf=ldf.copy()\n",
    "    \n",
    "    #Conglomerate pitcher stats\n",
    "    nldf.set_index(['pID'], inplace=True)\n",
    "    for col in ['AB', 'PA', 'H', 'TB', 'SAC', 'SO', 'W']:\n",
    "        nldf['ovp_'+col] = ldfp[col].sum()\n",
    "    nldf['ovp_AVG'] = nldf['ovp_H']/nldf['ovp_AB']\n",
    "    nldf['ovp_FACED']= ldfp.AB.count()\n",
    "    nldf['ovp_OBP'] = (nldf['ovp_H'] + nldf['ovp_W'])/nldf['ovp_PA']\n",
    "    for col in ['SO', 'W', 'H']:\n",
    "        nldf['ovp_' + col + '_PCT'] = nldf['ovp_' + col] / nldf['ovp_PA']\n",
    "    nldf.reset_index(inplace=True)\n",
    "    \n",
    "    #Conglomerate batter stats\n",
    "    nldf.set_index(['bID'], inplace=True)\n",
    "    for col in ['AB', 'PA', 'H', 'TB', 'SAC', 'SO', 'W']:\n",
    "        nldf['ov_'+col] = ldfb[col].sum()\n",
    "    nldf['ov_AVG'] = nldf['ov_H']/nldf['ov_AB']\n",
    "    nldf['ov_FACED']= ldfb.AB.count()\n",
    "    nldf['ov_OBP'] = (nldf['ov_H'] + nldf['ov_W'])/nldf['ov_PA']\n",
    "    for col in ['SO', 'W', 'H']:\n",
    "        nldf['ov_' + col + '_PCT'] = nldf['ov_' + col] / nldf['ov_PA']\n",
    "    nldf.reset_index(inplace=True)\n",
    "    return nldf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bID</th>\n",
       "      <th>pID</th>\n",
       "      <th>AB</th>\n",
       "      <th>H</th>\n",
       "      <th>PA</th>\n",
       "      <th>RL</th>\n",
       "      <th>SAC</th>\n",
       "      <th>SO</th>\n",
       "      <th>TB</th>\n",
       "      <th>W</th>\n",
       "      <th>matchID</th>\n",
       "      <th>AVG</th>\n",
       "      <th>OBP</th>\n",
       "      <th>ov_AB</th>\n",
       "      <th>ov_H</th>\n",
       "      <th>ov_PA</th>\n",
       "      <th>ov_SAC</th>\n",
       "      <th>ov_SO</th>\n",
       "      <th>ov_TB</th>\n",
       "      <th>ov_W</th>\n",
       "      <th>ov_AVG</th>\n",
       "      <th>ov_OBP</th>\n",
       "      <th>ov_FACED</th>\n",
       "      <th>ov_SO_PCT</th>\n",
       "      <th>ov_W_PCT</th>\n",
       "      <th>ov_H_PCT</th>\n",
       "      <th>ovp_AB</th>\n",
       "      <th>ovp_H</th>\n",
       "      <th>ovp_PA</th>\n",
       "      <th>ovp_SAC</th>\n",
       "      <th>ovp_SO</th>\n",
       "      <th>ovp_TB</th>\n",
       "      <th>ovp_W</th>\n",
       "      <th>ovp_AVG</th>\n",
       "      <th>ovp_OBP</th>\n",
       "      <th>ovp_FACED</th>\n",
       "      <th>ovp_SO_PCT</th>\n",
       "      <th>ovp_W_PCT</th>\n",
       "      <th>ovp_H_PCT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aberb001</td>\n",
       "      <td>bellr003</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>R</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>aberb001_bellr003</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>359</td>\n",
       "      <td>78</td>\n",
       "      <td>385</td>\n",
       "      <td>4</td>\n",
       "      <td>41</td>\n",
       "      <td>120</td>\n",
       "      <td>26</td>\n",
       "      <td>0.21727</td>\n",
       "      <td>0.27013</td>\n",
       "      <td>30</td>\n",
       "      <td>0.106494</td>\n",
       "      <td>0.067532</td>\n",
       "      <td>0.202597</td>\n",
       "      <td>1340</td>\n",
       "      <td>416</td>\n",
       "      <td>1510</td>\n",
       "      <td>20</td>\n",
       "      <td>200</td>\n",
       "      <td>957</td>\n",
       "      <td>170</td>\n",
       "      <td>0.310448</td>\n",
       "      <td>0.388079</td>\n",
       "      <td>118</td>\n",
       "      <td>0.132450</td>\n",
       "      <td>0.112583</td>\n",
       "      <td>0.275497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aberb001</td>\n",
       "      <td>buehm001</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>L</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>aberb001_buehm001</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>359</td>\n",
       "      <td>78</td>\n",
       "      <td>385</td>\n",
       "      <td>4</td>\n",
       "      <td>41</td>\n",
       "      <td>120</td>\n",
       "      <td>26</td>\n",
       "      <td>0.21727</td>\n",
       "      <td>0.27013</td>\n",
       "      <td>30</td>\n",
       "      <td>0.106494</td>\n",
       "      <td>0.067532</td>\n",
       "      <td>0.202597</td>\n",
       "      <td>8822</td>\n",
       "      <td>2439</td>\n",
       "      <td>9460</td>\n",
       "      <td>115</td>\n",
       "      <td>1280</td>\n",
       "      <td>4535</td>\n",
       "      <td>638</td>\n",
       "      <td>0.276468</td>\n",
       "      <td>0.325264</td>\n",
       "      <td>410</td>\n",
       "      <td>0.135307</td>\n",
       "      <td>0.067442</td>\n",
       "      <td>0.257822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aberb001</td>\n",
       "      <td>burkj001</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>R</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>aberb001_burkj001</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>359</td>\n",
       "      <td>78</td>\n",
       "      <td>385</td>\n",
       "      <td>4</td>\n",
       "      <td>41</td>\n",
       "      <td>120</td>\n",
       "      <td>26</td>\n",
       "      <td>0.21727</td>\n",
       "      <td>0.27013</td>\n",
       "      <td>30</td>\n",
       "      <td>0.106494</td>\n",
       "      <td>0.067532</td>\n",
       "      <td>0.202597</td>\n",
       "      <td>3906</td>\n",
       "      <td>1122</td>\n",
       "      <td>4261</td>\n",
       "      <td>43</td>\n",
       "      <td>663</td>\n",
       "      <td>2140</td>\n",
       "      <td>355</td>\n",
       "      <td>0.287250</td>\n",
       "      <td>0.346632</td>\n",
       "      <td>209</td>\n",
       "      <td>0.155597</td>\n",
       "      <td>0.083314</td>\n",
       "      <td>0.263318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aberb001</td>\n",
       "      <td>castf001</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>R</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>aberb001_castf001</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>359</td>\n",
       "      <td>78</td>\n",
       "      <td>385</td>\n",
       "      <td>4</td>\n",
       "      <td>41</td>\n",
       "      <td>120</td>\n",
       "      <td>26</td>\n",
       "      <td>0.21727</td>\n",
       "      <td>0.27013</td>\n",
       "      <td>30</td>\n",
       "      <td>0.106494</td>\n",
       "      <td>0.067532</td>\n",
       "      <td>0.202597</td>\n",
       "      <td>2157</td>\n",
       "      <td>608</td>\n",
       "      <td>2388</td>\n",
       "      <td>29</td>\n",
       "      <td>344</td>\n",
       "      <td>1206</td>\n",
       "      <td>231</td>\n",
       "      <td>0.281873</td>\n",
       "      <td>0.351340</td>\n",
       "      <td>144</td>\n",
       "      <td>0.144054</td>\n",
       "      <td>0.096734</td>\n",
       "      <td>0.254606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aberb001</td>\n",
       "      <td>clemr001</td>\n",
       "      <td>25</td>\n",
       "      <td>7</td>\n",
       "      <td>26</td>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>aberb001_clemr001</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>359</td>\n",
       "      <td>78</td>\n",
       "      <td>385</td>\n",
       "      <td>4</td>\n",
       "      <td>41</td>\n",
       "      <td>120</td>\n",
       "      <td>26</td>\n",
       "      <td>0.21727</td>\n",
       "      <td>0.27013</td>\n",
       "      <td>30</td>\n",
       "      <td>0.106494</td>\n",
       "      <td>0.067532</td>\n",
       "      <td>0.202597</td>\n",
       "      <td>6103</td>\n",
       "      <td>1493</td>\n",
       "      <td>6774</td>\n",
       "      <td>60</td>\n",
       "      <td>1477</td>\n",
       "      <td>2796</td>\n",
       "      <td>671</td>\n",
       "      <td>0.244634</td>\n",
       "      <td>0.319457</td>\n",
       "      <td>263</td>\n",
       "      <td>0.218040</td>\n",
       "      <td>0.099055</td>\n",
       "      <td>0.220402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        bID       pID  AB  H  PA RL  SAC  SO  TB  W            matchID       AVG       OBP  ov_AB  ov_H  ov_PA  ov_SAC  ov_SO  ov_TB  ov_W   ov_AVG   ov_OBP  ov_FACED  ov_SO_PCT  ov_W_PCT  ov_H_PCT  ovp_AB  ovp_H  ovp_PA  ovp_SAC  ovp_SO  ovp_TB  ovp_W   ovp_AVG   ovp_OBP  ovp_FACED  ovp_SO_PCT  ovp_W_PCT  ovp_H_PCT\n",
       "0  aberb001  bellr003   9  1  10  R    0   0   1  1  aberb001_bellr003  0.111111  0.200000    359    78    385       4     41    120    26  0.21727  0.27013        30   0.106494  0.067532  0.202597    1340    416    1510       20     200     957    170  0.310448  0.388079        118    0.132450   0.112583   0.275497\n",
       "1  aberb001  buehm001  13  2  14  L    0   3   6  1  aberb001_buehm001  0.153846  0.214286    359    78    385       4     41    120    26  0.21727  0.27013        30   0.106494  0.067532  0.202597    8822   2439    9460      115    1280    4535    638  0.276468  0.325264        410    0.135307   0.067442   0.257822\n",
       "2  aberb001  burkj001   8  2   9  R    0   1   2  1  aberb001_burkj001  0.250000  0.333333    359    78    385       4     41    120    26  0.21727  0.27013        30   0.106494  0.067532  0.202597    3906   1122    4261       43     663    2140    355  0.287250  0.346632        209    0.155597   0.083314   0.263318\n",
       "3  aberb001  castf001   7  1  11  R    0   0   1  4  aberb001_castf001  0.142857  0.454545    359    78    385       4     41    120    26  0.21727  0.27013        30   0.106494  0.067532  0.202597    2157    608    2388       29     344    1206    231  0.281873  0.351340        144    0.144054   0.096734   0.254606\n",
       "4  aberb001  clemr001  25  7  26  R    1   2   9  1  aberb001_clemr001  0.280000  0.307692    359    78    385       4     41    120    26  0.21727  0.27013        30   0.106494  0.067532  0.202597    6103   1493    6774       60    1477    2796    671  0.244634  0.319457        263    0.218040   0.099055   0.220402"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindf=recompute_frame(traindf)\n",
    "validatedf=recompute_frame(validatedf)\n",
    "testdf=recompute_frame(testdf)\n",
    "validatedf=validatedf[['bID', 'pID','AVG']]\n",
    "testdf=testdf[['bID', 'pID', 'AVG']]\n",
    "traindf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compute_supports(df, upids):\n",
    "    ubids=df.bID.unique()\n",
    "    pitch = df.groupby('pID').bID.unique()\n",
    "    bdict={}\n",
    "    for e,v in zip(pitch.index.values, pitch.values):\n",
    "        bdict[e] = np.array([item in v for item in ubids])\n",
    "    pitchers=upids\n",
    "    supports=[]\n",
    "    supports_matrix = [[[] for i in range(len(pitchers))] for j in range(len(pitchers))]\n",
    "    for i,p1 in enumerate(pitchers):\n",
    "        for j,p2 in enumerate(pitchers):\n",
    "            if  i < j:\n",
    "                common_batters = set(pitch[p1]).intersection(set(pitch[p2]))\n",
    "                n = len(common_batters)\n",
    "                supports.append(n)\n",
    "                supports_matrix[i][j] = common_batters\n",
    "                supports_matrix[j][i] = common_batters\n",
    "    print \"mean support\",np.mean(supports), \"median support\", np.median(supports)\n",
    "    return supports, bdict, supports_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ubids=traindf.bID.unique()#unique-user-ids\n",
    "upids=traindf.pID.unique()#unique-item-ids\n",
    "ubidmap={v:k for k,v in enumerate(ubids)}#of length U\n",
    "upidmap={v:k for k,v in enumerate(upids)}#of length M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#for each restaurant get the unique userids who rated it\n",
    "# pitch = traindf.groupby('pID').bID.unique()\n",
    "# restaurants=upids\n",
    "# lres=len(restaurants)\n",
    "# supports=[[[] for i in range(lres)] for i in range(lres)]\n",
    "# supporthistlist=[]\n",
    "# for i,rest1 in enumerate(restaurants):\n",
    "#     for j,rest2 in enumerate(restaurants):\n",
    "#         if  i <= j:#its symmetric\n",
    "#             if rest1==rest2:\n",
    "#                 common_reviewers=pitch[rest1]\n",
    "#             else:\n",
    "#                 common_reviewers = set(pitch[rest1]).intersection(set(pitch[rest2]))\n",
    "#                 supporthistlist.append(len(common_reviewers))\n",
    "#             supports[i][j]=common_reviewers\n",
    "#             supports[j][i]=common_reviewers\n",
    "# print \"Mean and Median support is:\",np.mean(supporthistlist), np.median(supporthistlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Matchups 101036\n",
      "Number of Batters 910\n",
      "Number of Pitchers 1297\n"
     ]
    }
   ],
   "source": [
    "print \"Number of Matchups\",traindf.shape[0]\n",
    "print \"Number of Batters\", traindf.bID.unique().shape[0]\n",
    "print \"Number of Pitchers\", traindf.pID.unique().shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean support 11.593010223 median support 4.0\n"
     ]
    }
   ],
   "source": [
    "s,d, supports_matrix =compute_supports(traindf, upids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import cPickle as pickle\n",
    "# pickle.dump(supports_matrix,open('data/supports_matrix.p','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#supports_matrix = pickle.load(open('data/supports_matrix.p','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Database:\n",
    "    \"A class representing a database of similarities and common supports\"\n",
    "    \n",
    "    def __init__(self, rindexmap, supports):\n",
    "        \"the constructor, takes a map of restaurant id's to integers\"\n",
    "        database={}\n",
    "        self.rindexmap=rindexmap\n",
    "        self.supports=supports\n",
    "        l_keys=len(self.rindexmap.keys())\n",
    "        self.database_sim=np.zeros([l_keys,l_keys])\n",
    "        self.database_sup=np.zeros([l_keys, l_keys], dtype=np.int)\n",
    "\n",
    "    def set_supports(self, supports):\n",
    "        self.supports=supports\n",
    "        \n",
    "    def get(self, b1, b2):\n",
    "        \"returns a tuple of similarity,common_support given two business ids\"\n",
    "        sim=self.database_sim[self.rindexmap[b1]][self.rindexmap[b2]]\n",
    "        nsup=self.database_sup[self.rindexmap[b1]][self.rindexmap[b2]]\n",
    "        return (sim, nsup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# db=Database(upidmap, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mapper1(row):\n",
    "    return row[1], (row[2], row[12], row[34])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def combiner(items):\n",
    "    indict={}\n",
    "    for key, value in items:\n",
    "        if not indict.has_key(key):\n",
    "            indict[key]=[]\n",
    "        indict[key].append(value)\n",
    "    return indict.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reducer1(the_input):\n",
    "    bID, values = the_input\n",
    "    avgs=[]\n",
    "    for pID,AVG,ov_AVG in values:\n",
    "        avgs.append((pID,(AVG, ov_AVG)))\n",
    "    return bID, avgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from itertools import combinations_with_replacement\n",
    "def mapper2(list_input):\n",
    "    nlist = []\n",
    "    comb = list(combinations_with_replacement(list_input[1], 2))\n",
    "    for item in comb:\n",
    "        if item[0][0] > item[1][0]:\n",
    "            biz_pair = item[1][0], item[0][0]\n",
    "            star_pair = item[1][1], item[0][1]\n",
    "        else:\n",
    "            biz_pair = item[0][0], item[1][0]\n",
    "            star_pair = item[0][1], item[1][1]\n",
    "        tup = (biz_pair, star_pair)\n",
    "        nlist.append(tup)\n",
    "    return nlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def combiner_list(itemslist):\n",
    "    indict={}\n",
    "    for items in itemslist:\n",
    "        for key, value in items:\n",
    "            if not indict.has_key(key):\n",
    "                indict[key]=[]\n",
    "            indict[key].append(value)\n",
    "    return indict.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reducer2(item_dict):\n",
    "    p1_id = item_dict[0][0]\n",
    "    p2_id = item_dict[0][1]\n",
    "#     AVG_1 = [x[0][0] for x in item_dict[1]]\n",
    "#     AVG_2 = [x[1][0] for x in item_dict[1]]\n",
    "#     ov_AVG_1 = [x[0][1] for x in item_dict[1]]\n",
    "#     ov_AVG_2 = [x[1][1] for x in item_dict[1]]\n",
    "    n_common = len(item_dict[1])\n",
    "    print('a')\n",
    "    p1 = smalldf[smalldf.pID==p1_id]#{'ov_AVG': ov_AVG_1, 'AVG': AVG_1}\n",
    "    p2 = smalldf[smalldf.pID==p1_id]#{'ov_AVG': ov_AVG_2, 'AVG': AVG_2}\n",
    "    rho = pitcher_sim(p1, p2, n_common)\n",
    "    return (p1_id, p2_id),(rho, n_common)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def map_reduce(tuples):\n",
    "    mapped1=map(mapper1, tuples)\n",
    "    combine1=combiner(mapped1)\n",
    "    reduced1=reduce(lambda x,y: x + [reducer1(y)], combine1, [])\n",
    "    mapped2=map(mapper2,reduced1)\n",
    "    combine2=combiner_list(mapped2)\n",
    "    output=reduce(lambda x,y: x + [reducer2(y)], combine2, [])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# tuples=traindf.itertuples()\n",
    "# sims2=map_reduce(tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import cPickle as pickle\n",
    "# pickle.dump(sims2,open('sims2.p','wb'))\n",
    "# #sims2 = pickle.load(open('sims2.p','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def populate_from_mr(db, df, mapredlist):\n",
    "    for tpair,vpair in mapredlist:\n",
    "        i1=db.rindexmap[tpair[0]]\n",
    "        i2=db.rindexmap[tpair[1]]\n",
    "        db.database_sim[i1][i2]=vpair[0]\n",
    "        db.database_sup[i1][i2]=vpair[1]\n",
    "        db.database_sim[i2][i1]=vpair[0]\n",
    "        db.database_sup[i2][i1]=vpair[1]\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# populate_from_mr(db, traindf, sims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "db2=Database(upidmap, supports_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_restaurant_reviews(pID, df, set_of_batters):\n",
    "    \"\"\"\n",
    "    given a pitcher id and a set of batters, return the sub-dataframe of their\n",
    "    averages.\n",
    "    \"\"\"\n",
    "    mask = (df.bID.isin(set_of_batters)) & (df.pID==pID)\n",
    "    avgs = df[mask]\n",
    "    avgs = avgs[avgs.bID.duplicated()==False]\n",
    "    return avgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calculate_similarity(db, df, p1, p2, similarity_func):\n",
    "    # find common reviewers\n",
    "    common_reviewers = db.supports[db.rindexmap[p1]][db.rindexmap[p2]]\n",
    "    n_common=len(common_reviewers)\n",
    "    if p1==p2:\n",
    "        return 1., n_common\n",
    "    #get reviews\n",
    "    if n_common==0:\n",
    "        return 0., n_common\n",
    "    p1_rows = get_restaurant_reviews(p1, df, common_reviewers)\n",
    "    p2_rows = get_restaurant_reviews(p2, df, common_reviewers)\n",
    "    sim=similarity_func(p1_rows, p2_rows, n_common)\n",
    "    return sim, n_common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def populate_by_calculating(db, df, similarity_func):\n",
    "    \"\"\"\n",
    "    a populator for every pair of businesses in df. takes similarity_func like\n",
    "    pearson_sim as argument\n",
    "    \"\"\"\n",
    "    items=db.rindexmap.items()\n",
    "    total = len(items)**2\n",
    "    count = 0\n",
    "    start = time.time()\n",
    "    for b1, i1 in items:\n",
    "        for b2, i2 in items:\n",
    "            count += 1\n",
    "            if (((10000*count)/total) > ((10000*(count-1))/total)):\n",
    "                frac_done = count/float(total)\n",
    "                time_elapsed = (time.time() - start) / (60.)\n",
    "                remaining = ((1./frac_done)-1.)*time_elapsed\n",
    "                print('%.3f percent done | elapsed: %.1f min | remaining: %.2f hour'%(frac_done *100, time_elapsed, remaining/60))\n",
    "            if i1 <= i2:\n",
    "                sim, nsup=calculate_similarity(db, df, b1, b2, similarity_func)\n",
    "                db.database_sim[i1][i2]=sim\n",
    "                db.database_sim[i2][i1]=sim\n",
    "                db.database_sup[i1][i2]=nsup\n",
    "                db.database_sup[i2][i1]=nsup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.010 percent done | elapsed: 0.6 min | remaining: 91.40 hour\n",
      "0.020 percent done | elapsed: 1.1 min | remaining: 92.23 hour\n",
      "0.030 percent done | elapsed: 1.9 min | remaining: 106.95 hour\n",
      "0.040 percent done | elapsed: 2.6 min | remaining: 107.55 hour\n",
      "0.050 percent done | elapsed: 3.2 min | remaining: 106.71 hour\n",
      "0.060 percent done | elapsed: 3.7 min | remaining: 102.46 hour\n",
      "0.070 percent done | elapsed: 4.5 min | remaining: 107.88 hour\n",
      "0.080 percent done | elapsed: 5.4 min | remaining: 112.36 hour\n",
      "0.090 percent done | elapsed: 6.7 min | remaining: 123.99 hour\n",
      "0.100 percent done | elapsed: 8.2 min | remaining: 136.01 hour\n",
      "0.110 percent done | elapsed: 9.6 min | remaining: 146.00 hour\n",
      "0.120 percent done | elapsed: 11.6 min | remaining: 160.83 hour\n",
      "0.130 percent done | elapsed: 13.0 min | remaining: 166.24 hour\n",
      "0.140 percent done | elapsed: 14.5 min | remaining: 172.58 hour\n",
      "0.150 percent done | elapsed: 16.0 min | remaining: 177.72 hour"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bcook/anaconda/lib/python2.7/site-packages/IPython/kernel/__main__.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/bcook/anaconda/lib/python2.7/site-packages/IPython/kernel/__main__.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.160 percent done | elapsed: 17.0 min | remaining: 176.78 hour\n",
      "0.170 percent done | elapsed: 17.3 min | remaining: 169.68 hour\n",
      "0.180 percent done | elapsed: 17.5 min | remaining: 161.36 hour\n",
      "0.190 percent done | elapsed: 17.7 min | remaining: 155.13 hour\n",
      "0.200 percent done | elapsed: 18.2 min | remaining: 150.97 hour\n",
      "0.210 percent done | elapsed: 18.6 min | remaining: 147.22 hour\n",
      "0.220 percent done | elapsed: 18.9 min | remaining: 142.88 hour\n",
      "0.230 percent done | elapsed: 19.1 min | remaining: 138.38 hour\n",
      "0.240 percent done | elapsed: 19.3 min | remaining: 133.78 hour\n",
      "0.250 percent done | elapsed: 19.4 min | remaining: 129.06 hour\n",
      "0.260 percent done | elapsed: 19.5 min | remaining: 124.71 hour\n",
      "0.270 percent done | elapsed: 19.7 min | remaining: 120.97 hour\n",
      "0.280 percent done | elapsed: 19.8 min | remaining: 117.33 hour\n",
      "0.290 percent done | elapsed: 20.0 min | remaining: 114.38 hour\n",
      "0.300 percent done | elapsed: 20.1 min | remaining: 111.09 hour\n",
      "0.310 percent done | elapsed: 20.2 min | remaining: 108.41 hour\n",
      "0.320 percent done | elapsed: 20.6 min | remaining: 107.13 hour\n",
      "0.330 percent done | elapsed: 20.8 min | remaining: 104.87 hour\n",
      "0.340 percent done | elapsed: 21.2 min | remaining: 103.65 hour\n",
      "0.350 percent done | elapsed: 21.3 min | remaining: 101.26 hour\n",
      "0.360 percent done | elapsed: 21.9 min | remaining: 100.90 hour\n",
      "0.370 percent done | elapsed: 22.0 min | remaining: 98.69 hour\n",
      "0.380 percent done | elapsed: 22.2 min | remaining: 97.04 hour\n",
      "0.390 percent done | elapsed: 22.8 min | remaining: 97.22 hour\n",
      "0.400 percent done | elapsed: 24.1 min | remaining: 100.19 hour\n",
      "0.410 percent done | elapsed: 25.5 min | remaining: 103.26 hour\n",
      "0.420 percent done | elapsed: 26.8 min | remaining: 106.05 hour\n",
      "0.430 percent done | elapsed: 28.3 min | remaining: 109.38 hour\n",
      "0.440 percent done | elapsed: 29.5 min | remaining: 111.26 hour\n",
      "0.450 percent done | elapsed: 30.9 min | remaining: 113.79 hour\n",
      "0.460 percent done | elapsed: 32.2 min | remaining: 116.21 hour\n",
      "0.470 percent done | elapsed: 33.1 min | remaining: 116.86 hour\n",
      "0.480 percent done | elapsed: 34.1 min | remaining: 117.96 hour\n",
      "0.490 percent done | elapsed: 35.2 min | remaining: 119.17 hour\n",
      "0.500 percent done | elapsed: 36.3 min | remaining: 120.44 hour\n",
      "0.510 percent done | elapsed: 37.4 min | remaining: 121.73 hour\n",
      "0.520 percent done | elapsed: 38.5 min | remaining: 122.60 hour\n",
      "0.530 percent done | elapsed: 39.6 min | remaining: 123.74 hour\n",
      "0.540 percent done | elapsed: 40.8 min | remaining: 125.26 hour\n",
      "0.550 percent done | elapsed: 41.1 min | remaining: 123.70 hour\n",
      "0.560 percent done | elapsed: 41.5 min | remaining: 122.93 hour\n",
      "0.570 percent done | elapsed: 42.1 min | remaining: 122.30 hour\n",
      "0.580 percent done | elapsed: 42.6 min | remaining: 121.70 hour\n",
      "0.590 percent done | elapsed: 43.0 min | remaining: 120.83 hour\n",
      "0.600 percent done | elapsed: 43.5 min | remaining: 120.20 hour\n",
      "0.610 percent done | elapsed: 43.9 min | remaining: 119.13 hour\n",
      "0.620 percent done | elapsed: 44.5 min | remaining: 118.85 hour"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "populate_by_calculating(db2, traindf, pitcher_sim)                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import cPickle as pickle\n",
    "#pickle.dump(db2,open('db2.p','wb'))\n",
    "db2 = pickle.load(open('db2.p','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['dotsr001', 'bannf001', 'forsb001', ..., 'hernl003', 'hudst001',\n",
       "       'buehm001'], dtype=object)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smalldf.sort('ovp_FACED').pID.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.020463161725546037, 209)\n"
     ]
    }
   ],
   "source": [
    "tpair=('buehm001', 'hudst001') # Mark Buehrle vs. Tim Hudson\n",
    "print db.get(tpair[0],tpair[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, axis = plt.subplots(figsize=(8,5))\n",
    "sims = db.database_sim.flatten()\n",
    "axis.hist(sims[sims>=0], bins=20, normed=True)\n",
    "axis.set_xlabel('Similarities')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shrunk_sim(sim, n_common, reg=3.):\n",
    "    \"takes a similarity and shrinks it down by using the regularizer\"\n",
    "    ssim=(n_common*sim)/(n_common+reg)\n",
    "    return ssim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function\n",
    "--------\n",
    "knearest\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "restaurant_id : string\n",
    "    The id of the restaurant whose nearest neighbors we want\n",
    "set_of_restaurants : array\n",
    "    The set of restaurants from which we want to find the nearest neighbors\n",
    "dbase : instance of Database class.\n",
    "    A database of similarities, on which the get method can be used to get the similarity\n",
    "  of two businesses. e.g. dbase.get(rid1,rid2)\n",
    "k : int\n",
    "    the number of nearest neighbors desired, default 7\n",
    "reg: float\n",
    "    the regularization.\n",
    "    \n",
    "  \n",
    "Returns\n",
    "--------\n",
    "A sorted list\n",
    "    of the top k similar restaurants. The list is a list of tuples\n",
    "    (business_id, shrunken similarity, common support).\n",
    "\"\"\"\n",
    "from operator import itemgetter\n",
    "def knearest(restaurant_id, set_of_restaurants, dbase, k=7, reg=3.):\n",
    "    \"\"\"\n",
    "    Given a restaurant_id, dataframe, and database, get a sorted list of the\n",
    "    k most similar restaurants from the set of restaurants.\n",
    "    \"\"\"\n",
    "    similars=[]\n",
    "    for other_rest_id in set_of_restaurants:\n",
    "        if other_rest_id!=restaurant_id:\n",
    "            sim, nc=dbase.get(restaurant_id, other_rest_id)\n",
    "            ssim=shrunk_sim(sim, nc, reg=reg)\n",
    "            simdist=(1. - ssim)/2.\n",
    "            similars.append((other_rest_id, simdist, nc ))\n",
    "    similars=sorted(similars, key=itemgetter(1))\n",
    "    return similars[0:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_users_restaurants(df, b_id):\n",
    "    dfbatter=df[df.bID==b_id]\n",
    "    dfbatterdedup=dfbatter.drop_duplicates('pID')\n",
    "    return dict(zip(dfbatterdedup.pID.values, dfbatterdedup.AVG.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function\n",
    "--------\n",
    "rating\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "set_of_restaurants: Dictionary\n",
    "    The dictionary of restaurant: star-rating pairs you want to make the prediction from.\n",
    "    This would be the output of a function like get_users_restaurants\n",
    "train_map: Dictionary\n",
    "    A dictionary with keys mean, users and items which have estimates of\n",
    "    overall average or intercept, user coefficients(averages), and\n",
    "    item coefficients(averages) respectively\n",
    "dbase : instance of Database class.\n",
    "    A database of similarities, on which the get method can be used to get the similarity\n",
    "  of two businessed. e.g. dbase.get(rid1,rid2)\n",
    "restaurant_id : string\n",
    "    The id of the restaurant whose nearest neighbors we want\n",
    "user_id : string\n",
    "    The id of the user, in whose reviewed restaurants we want to find the neighbors\n",
    "k : int\n",
    "    the number of nearest neighbors desired, default 7\n",
    "reg: float\n",
    "    the regularization.\n",
    "    \n",
    "  \n",
    "Returns\n",
    "--------\n",
    "A float\n",
    "    which is the imputed rating that we predict that user_id will make for restaurant_id\n",
    "    \n",
    "Notes\n",
    "--------\n",
    "If the sum of scores is 0, return the baseline estimate of the ranking.\n",
    "\"\"\"\n",
    "#your code here\n",
    "# Note: this function was inspired in part by the solutions to the 2013 hw4\n",
    "def rating(set_of_restaurants, train_map, dbase, restaurant_id, user_id, k=7, reg=3.):\n",
    "    mu=train_map['mean']\n",
    "    user_bias = train_map['batters'][user_id]\n",
    "    nsum=0.\n",
    "    scoresum=0.\n",
    "    nears=knearest(restaurant_id, set_of_restaurants, dbase, k=k, reg=reg)\n",
    "    restaurant_bias=train_map['pitchers'][restaurant_id]\n",
    "    scores=[]\n",
    "    for r,s,nc in nears:\n",
    "        ssim = 1-s\n",
    "        scoresum=scoresum+ssim\n",
    "        scores.append(ssim)\n",
    "        r_biases = train_map['pitchers'][r]\n",
    "        r_stars = set_of_restaurants[r]\n",
    "        rminusb=(r_stars - (r_biases + user_bias + mu))\n",
    "        nsum=nsum+ssim*rminusb\n",
    "    baseline=(user_bias +restaurant_bias + mu)\n",
    "    if scoresum > 0.:\n",
    "        val =  nsum/scoresum + baseline\n",
    "    else:\n",
    "        val=baseline\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainuser=traindf.loc[100].bID\n",
    "try:\n",
    "    testrest=testdf[testdf.bID==trainuser].pID.values[0]\n",
    "except:\n",
    "    testrest=testdf[testdf.bID==trainuser].pID\n",
    "print trainuser, testrest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testdf[testdf.bID=='abreb001'].pID.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "traindf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_actual(df, userid, bizid):\n",
    "    return df[(df.bID==userid) & (df.pID==bizid)]['AVG'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print \"Actual\", get_actual(testdf, trainuser, testrest)\n",
    "print \"Predicted\",rating(get_users_restaurants(traindf, trainuser), train_avgs, db, testrest, trainuser, k=2, reg=3.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_ratings_user_nbd(indf, traindf, train_map, db, k=2, reg=3.):\n",
    "    zips=zip(indf.pID, indf.bID, indf.AVG)\n",
    "    preds=[]\n",
    "    actuals=[]\n",
    "    for (r,u,actual) in zips:\n",
    "        pred=rating(get_users_restaurants(traindf, u),train_map, db, r,u, k, reg)\n",
    "        preds.append(pred)\n",
    "        actuals.append(actual)\n",
    "    return np.array(preds), np.array(actuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "pt, at = get_ratings_user_nbd(traindf, traindf, train_avgs, db, k=6, reg=4.)\n",
    "compare_results(at,pt, model=\"knn(user) on training k=6, reg=4\", predicteds=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "k = range(40,100,10)\n",
    "reg = range(1,12,2)\n",
    "rmsedict = {}\n",
    "for kval in k:\n",
    "    for regval in reg:\n",
    "        pt, at = get_ratings_user_nbd(validatedf, traindf, train_avgs, db, k=kval, reg=regval)\n",
    "        rmse = get_rmse(at, pt)\n",
    "        key = (kval, regval)\n",
    "        rmsedict[key] = rmse\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "     \n",
    "mintup=min(rmsedict, key=rmsedict.get)\n",
    "mintup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bestk, bestreg = mintup\n",
    "predictions[\"knn\"], atknn = get_ratings_user_nbd(testdf, traindf,train_avgs, db, k=bestk, reg=bestreg)\n",
    "predictions_valid[\"knn\"], atvalid = get_ratings_user_nbd(traindf, traindf, train_avgs, db, k=bestk, reg=bestreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ax, rmse_knn = compare_results(testdf.AVG, predictions['knn'], model=(\"knn(user) on test k=\" + str(bestk) + \", reg=\" + str(bestreg)), predicteds=True)\n",
    "# compare_results(testdf.stars,predictions['baseline'], model=\"baseline\", predicteds=True, onsame=ax)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
